{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 参考文献\n",
    "+ https://zhuanlan.zhihu.com/p/481256924\n",
    "+ code:https://github.com/vztu/maxim-pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 优势\n",
    "首先，MAXIM在任意大的图像上具有全局接受野，时间复杂度为线性。\n",
    "\n",
    "其次，它直接支持任意输入分辨率。\n",
    "\n",
    "最后，它提供了局部（Conv）和全局（MLP）块的平衡设计，表现优于SOTA方法，而无需进行大规模预训练"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 整体架构\n",
    "<img src=./img/model.png>\n",
    "\n",
    "由上图可以看出模型主要由MAXIM Backbone水平堆叠形成。模型loss主要有三个loss，由SAM产生。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SAM(nn.Module):\n",
    "    \"\"\"Supervised attention module for multi-stage training.\n",
    "    Introduced by MPRNet [CVPR2021]: https://github.com/swz30/MPRNet\n",
    "    \"\"\"\n",
    "    def __init__(self,features,output_channels=3,use_bias=True):\n",
    "        super().__init__()\n",
    "        self.features = features\n",
    "        self.output_channels = output_channels\n",
    "        self.bias = use_bias\n",
    "        self.conv1 = nn.Conv2d(self.features,self.features, kernel_size=(3, 3),bias=self.bias,padding=1)\n",
    "        self.conv2 = nn.Conv2d(self.features,self.output_channels, kernel_size=(3, 3),bias=self.bias,padding=1)\n",
    "        self.conv3 = nn.Conv2d(self.features,self.output_channels, kernel_size=(3, 3),bias=self.bias,padding=1)\n",
    "        self.conv4 = nn.Conv2d(self.output_channels,self.features, kernel_size=(3, 3),bias=self.bias,padding=1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    def forward(self, x,x_image):\n",
    "        \"\"\"Apply the SAM module to the input and features.\n",
    "        Args:\n",
    "          x: the output features from UNet decoder with shape (h, w, c)\n",
    "          x_image: the input image with shape (h, w, 3)\n",
    "          train: Whether it is training\n",
    "        Returns:\n",
    "          A tuple of tensors (x1, image) where (x1) is the sam features used for the\n",
    "            next stage, and (image) is the output restored image at current stage.\n",
    "        \"\"\"\n",
    "        # Get features\n",
    "        x1 = self.conv1(x)\n",
    "        # Output restored image X_s\n",
    "        if self.output_channels == 3:\n",
    "            image = self.conv2(x).permute(0,2,3,1) + x_image\n",
    "        else:\n",
    "            image = self.conv3(x)\n",
    "        # Get attention maps for features\n",
    "\n",
    "        x3 = self.conv4(image.permute(0,3,1,2))\n",
    "        x2 = self.sigmoid(x3)\n",
    "        # Get attended feature maps\n",
    "        x1 = x1 * x2\n",
    "        # Residual connection\n",
    "        x1 = x1 + x\n",
    "        return x1, image\n",
    "class MAXIM(nn.Module):\n",
    "    \"\"\"The MAXIM model function with multi-stage and multi-scale supervision.\n",
    "    For more model details, please check the CVPR paper:\n",
    "    MAXIM: MUlti-Axis MLP for Image Processing (https://arxiv.org/abs/2201.02973)\n",
    "    Attributes:\n",
    "      features: initial hidden dimension for the input resolution.\n",
    "      depth: the number of downsampling depth for the model.\n",
    "      num_stages: how many stages to use. It will also affects the output list.\n",
    "      num_groups: how many blocks each stage contains.\n",
    "      use_bias: whether to use bias in all the conv/mlp layers.\n",
    "      num_supervision_scales: the number of desired supervision scales.\n",
    "      lrelu_slope: the negative slope parameter in leaky_relu layers.\n",
    "      use_global_mlp: whether to use the multi-axis gated MLP block (MAB) in each\n",
    "        layer.\n",
    "      use_cross_gating: whether to use the cross-gating MLP block (CGB) in the\n",
    "        skip connections and multi-stage feature fusion layers.\n",
    "      high_res_stages: how many stages are specificied as high-res stages. The\n",
    "        rest (depth - high_res_stages) are called low_res_stages.\n",
    "      block_size_hr: the block_size parameter for high-res stages.\n",
    "      block_size_lr: the block_size parameter for low-res stages.\n",
    "      grid_size_hr: the grid_size parameter for high-res stages.\n",
    "      grid_size_lr: the grid_size parameter for low-res stages.\n",
    "      num_bottleneck_blocks: how many bottleneck blocks.\n",
    "      block_gmlp_factor: the input projection factor for block_gMLP layers.\n",
    "      grid_gmlp_factor: the input projection factor for grid_gMLP layers.\n",
    "      input_proj_factor: the input projection factor for the MAB block.\n",
    "      channels_reduction: the channel reduction factor for SE layer.\n",
    "      num_outputs: the output channels.\n",
    "      dropout_rate: Dropout rate.\n",
    "    Returns:\n",
    "      The output contains a list of arrays consisting of multi-stage multi-scale\n",
    "      outputs. For example, if num_stages = num_supervision_scales = 3 (the\n",
    "      model used in the paper), the output specs are: outputs =\n",
    "      [[output_stage1_scale1, output_stage1_scale2, output_stage1_scale3],\n",
    "       [output_stage2_scale1, output_stage2_scale2, output_stage2_scale3],\n",
    "       [output_stage3_scale1, output_stage3_scale2, output_stage3_scale3],]\n",
    "      The final output can be retrieved by outputs[-1][-1].\n",
    "    \"\"\"\n",
    "    def __init__(self,dim=1,dim2=1,dim4=1,num_channels=64,n1=64,n2=256,features=64,depth=3,num_stages=2,num_groups=1, use_bias=True, num_supervision_scales=int(1), lrelu_slope=0.2,\n",
    "                 use_global_mlp=True,use_cross_gating=True,high_res_stages=2,block_size_hr=(16,16),block_size_lr=(8,8),\n",
    "                 grid_size_hr=(16, 16),grid_size_lr=(8, 8),num_bottleneck_blocks=1,\n",
    "                block_gmlp_factor=2, grid_gmlp_factor=2,input_proj_factor=2, channels_reduction=4, num_outputs=3, dropout_rate=0.):\n",
    "        super().__init__()\n",
    "        self.features = features\n",
    "        self.depth = depth\n",
    "        self.num_stages = num_stages\n",
    "        self.num_groups = num_groups\n",
    "        self.num_supervision_scales = num_supervision_scales\n",
    "        self.high_res_stages = high_res_stages\n",
    "        self.block_size_hr = block_size_hr\n",
    "        self.block_size_lr = block_size_lr\n",
    "        self.grid_size_hr = grid_size_hr\n",
    "        self.grid_size_lr = grid_size_lr\n",
    "        self.num_bottleneck_blocks = num_bottleneck_blocks\n",
    "        self.num_outputs = num_outputs\n",
    "        self.lrelu_slope = lrelu_slope\n",
    "        self.block_gmlp_factor = block_gmlp_factor\n",
    "        self.grid_gmlp_factor = grid_gmlp_factor\n",
    "        self.input_proj_factor = input_proj_factor\n",
    "        self.channels_reduction = channels_reduction\n",
    "        self.use_global_mlp = use_global_mlp\n",
    "        self.use_cross_gating = use_cross_gating\n",
    "        self.bias = use_bias\n",
    "        self.drop = dropout_rate\n",
    "        self.conv1 = nn.Conv2d(3,self.features,kernel_size=(3,3),bias=self.bias,padding=1)\n",
    "        self.crossgatingblock1 = CrossGatingBlock(dim=dim,dim_v=64,dim_u=64,num_channels=num_channels,features=self.features,\n",
    "                                                 block_size=self.block_size_hr if 0 < self.high_res_stages else self.block_size_lr,\n",
    "                                                 grid_size=self.grid_size_hr if 0 < self.high_res_stages else self.block_size_lr,\n",
    "                                                dropout_rate=self.drop,input_proj_factor=self.input_proj_factor,upsample_y=False,\n",
    "                                                use_bias=self.bias ,idx=1)\n",
    "        self.conv2 = nn.Conv2d(self.features,self.features,kernel_size=(1,1),bias=self.bias,padding=1)\n",
    "        self.conv3 = nn.Conv2d(self.features,self.features*self.features,kernel_size=(3,3),bias=self.bias)\n",
    "        self.crossgatingblock2 = CrossGatingBlock(dim=dim,dim_v=1,dim_u=1,num_channels=num_channels,features=self.features*self.features,\n",
    "                                                 block_size=self.block_size_hr if 1 < self.high_res_stages else self.block_size_lr,\n",
    "                                                 grid_size=self.grid_size_hr if 1 < self.high_res_stages else self.block_size_lr,\n",
    "                                                dropout_rate=self.drop,input_proj_factor=self.input_proj_factor,upsample_y=False,\n",
    "                                                use_bias=self.bias)\n",
    "        self.conv4 = nn.Conv2d(self.features,self.features*self.features,kernel_size=(1,1),bias=self.bias ,padding=1)\n",
    "\n",
    "        self.unetencoderblock00 = UNetEncoderBlock(a=0,dim=0,n1=64,n2=64,num_channels=num_channels,features=self.features,num_groups=self.num_groups,downsample=True,\n",
    "            lrelu_slope=self.lrelu_slope,block_size=self.block_size_hr if 0 < self.high_res_stages else self.block_size_lr,\n",
    "            grid_size=self.grid_size_hr if 0 < self.high_res_stages else self.block_size_lr,block_gmlp_factor=self.block_gmlp_factor,\n",
    "            grid_gmlp_factor=self.grid_gmlp_factor,input_proj_factor=self.input_proj_factor,channels_reduction=self.channels_reduction,\n",
    "            use_global_mlp=self.use_global_mlp,dropout_rate=self.drop,use_bias=self.bias,use_cross_gating=False)#i=0 idx_stage=0\n",
    "        self.unetencoderblock10 = UNetEncoderBlock(a=1,dim=1,num_channels=2*num_channels,n1=128,n2=128,features=self.features,num_groups=self.num_groups,downsample=True,\n",
    "            lrelu_slope=self.lrelu_slope,block_size=self.block_size_hr if 1 < self.high_res_stages else self.block_size_lr,\n",
    "            grid_size=self.grid_size_hr if 1 < self.high_res_stages else self.block_size_lr,block_gmlp_factor=self.block_gmlp_factor,\n",
    "            grid_gmlp_factor=self.grid_gmlp_factor,input_proj_factor=self.input_proj_factor,channels_reduction=self.channels_reduction,\n",
    "            use_global_mlp=self.use_global_mlp,dropout_rate=self.drop,use_bias=self.bias,use_cross_gating=False)#i=1 idx_stage=0\n",
    "        self.unetencoderblock20 = UNetEncoderBlock(a=1,dim=dim4,num_channels=4*num_channels,n1=256,n2=256,features=2*self.features,num_groups=self.num_groups,downsample=True,\n",
    "            lrelu_slope=self.lrelu_slope,block_size=self.block_size_hr if 2 < self.high_res_stages else self.block_size_lr,\n",
    "            grid_size=self.grid_size_hr if 2 < self.high_res_stages else self.block_size_lr,block_gmlp_factor=self.block_gmlp_factor,\n",
    "            grid_gmlp_factor=self.grid_gmlp_factor,input_proj_factor=self.input_proj_factor,channels_reduction=self.channels_reduction,\n",
    "            use_global_mlp=self.use_global_mlp,dropout_rate=self.drop,use_bias=self.bias,use_cross_gating=False)#i=2 idx_stage=0\n",
    "\n",
    "        self.unetencoderblock01 = UNetEncoderBlock(a=0,dim=0,n1=n1,n2=64,num_channels=num_channels,features=self.features,num_groups=self.num_groups,downsample=True,\n",
    "            lrelu_slope=self.lrelu_slope,block_size=self.block_size_hr if 0 < self.high_res_stages else self.block_size_lr,\n",
    "            grid_size=self.grid_size_hr if 0 < self.high_res_stages else self.block_size_lr,block_gmlp_factor=self.block_gmlp_factor,\n",
    "            grid_gmlp_factor=self.grid_gmlp_factor,input_proj_factor=self.input_proj_factor,channels_reduction=self.channels_reduction,\n",
    "            use_global_mlp=self.use_global_mlp,dropout_rate=self.drop,use_bias=self.bias,use_cross_gating=True,idx=1)#i=0 idx_stage=1\n",
    "        self.unetencoderblock11 = UNetEncoderBlock(a=1,dim=1,n1=128,n2=128,num_channels=2*num_channels,features=self.features,num_groups=self.num_groups,downsample=True,\n",
    "            lrelu_slope=self.lrelu_slope,block_size=self.block_size_hr if 1 < self.high_res_stages else self.block_size_lr,\n",
    "            grid_size=self.grid_size_hr if 1 < self.high_res_stages else self.block_size_lr,block_gmlp_factor=self.block_gmlp_factor,\n",
    "            grid_gmlp_factor=self.grid_gmlp_factor,input_proj_factor=self.input_proj_factor,channels_reduction=self.channels_reduction,\n",
    "            use_global_mlp=self.use_global_mlp,dropout_rate=self.drop,use_bias=self.bias,use_cross_gating=True,idx=1,f=1,g=1,dim_u=128,dim_v=128)#i=1 idx_stage=1\n",
    "        self.unetencoderblock21 = UNetEncoderBlock(a=1,dim=dim4,n1=256,n2=256,num_channels=4*num_channels,features=2*self.features,num_groups=self.num_groups,downsample=True,\n",
    "            lrelu_slope=self.lrelu_slope,block_size=self.block_size_hr if 2 < self.high_res_stages else self.block_size_lr,\n",
    "            grid_size=self.grid_size_hr if 2 < self.high_res_stages else self.block_size_lr,block_gmlp_factor=self.block_gmlp_factor,\n",
    "            grid_gmlp_factor=self.grid_gmlp_factor,input_proj_factor=self.input_proj_factor,channels_reduction=self.channels_reduction,\n",
    "            use_global_mlp=self.use_global_mlp,dropout_rate=self.drop,use_bias=self.bias,use_cross_gating=True,idx=1,f=1,g=1,dim_u=256,dim_v=256)#i=2 idx_stage=1\n",
    "\n",
    "        self.bottleneckblock = BottleneckBlock(a=0,dim=dim,n1=256,n2=256,num_channels=256,block_size=self.block_size_lr,grid_size=self.block_size_lr,features=4 * self.features,\n",
    "            num_groups=self.num_groups,block_gmlp_factor=self.block_gmlp_factor,grid_gmlp_factor=self.grid_gmlp_factor,input_proj_factor=self.input_proj_factor,\n",
    "            dropout_rate=self.drop,use_bias=self.bias,channels_reduction=self.channels_reduction)\n",
    "\n",
    "\n",
    "        self.unsampleratio0 = UpSampleRatio(1*self.features,ratio=2**(-2),use_bias=self.bias,b=0)\n",
    "        self.unsampleratio1 = UpSampleRatio(2 * self.features,ratio=2**(-1),use_bias=self.bias,b=1)\n",
    "        self.unsampleratio2 = UpSampleRatio(4 * self.features,ratio=1,use_bias=self.bias,b=2)\n",
    "\n",
    "        self.unsampleratio3 = UpSampleRatio(1 * self.features,ratio=2**(-1),use_bias=self.bias,b = 1 )\n",
    "        self.unsampleratio4 = UpSampleRatio(2 * self.features,ratio=2**(0),use_bias=self.bias,b=2)\n",
    "        self.unsampleratio5 = UpSampleRatio(4 * self.features,ratio=2,use_bias=self.bias,b=3)\n",
    "\n",
    "        self.unsampleratio6 = UpSampleRatio(1 * self.features,ratio=1,use_bias=self.bias,b=2)\n",
    "        self.unsampleratio7 = UpSampleRatio(2 * self.features,ratio=2,use_bias=self.bias,b = 3)\n",
    "        self.unsampleratio8 = UpSampleRatio(4 * self.features,ratio=4,use_bias=self.bias,b=4)\n",
    "\n",
    "\n",
    "        self.crossgatingblock3 = CrossGatingBlock(dim=dim4,dim_v=256,dim_u=256,num_channels=4*num_channels,features=(2**2) * self.features,\n",
    "              block_size=self.block_size_hr if 2 < self.high_res_stages else self.block_size_lr,\n",
    "              grid_size=self.grid_size_hr if 2 < self.high_res_stages else self.block_size_lr,\n",
    "              input_proj_factor=self.input_proj_factor,\n",
    "              dropout_rate=self.drop,upsample_y=True,use_bias=self.bias)\n",
    "\n",
    "        self.conv5 = nn.Conv2d(384,4 * self.features,kernel_size=(1,1),bias=self.bias)\n",
    "        self.conv6 = nn.Conv2d((2**2) * self.features,(2**2) * self.features,kernel_size=(3,3),bias=self.bias,padding=1)\n",
    "\n",
    "\n",
    "        self.crossgatingblock4 = CrossGatingBlock(dim=dim2,dim_v=128,dim_u=128,num_channels=2*num_channels,features=(2 ** 1) * self.features,\n",
    "                                                  block_size=self.block_size_hr if 1 < self.high_res_stages else self.block_size_lr,\n",
    "                                                  grid_size=self.grid_size_hr if 1 < self.high_res_stages else self.block_size_lr,\n",
    "                                                  input_proj_factor=self.input_proj_factor,\n",
    "                                                  dropout_rate=self.drop, upsample_y=True, use_bias=self.bias,c=1)\n",
    "\n",
    "        self.conv7 = nn.Conv2d((2 ** 1) * self.features, (2 ** 1) * self.features, kernel_size=(1, 1), bias=self.bias,padding=1)\n",
    "        self.conv8 = nn.Conv2d((2 ** 1) * self.features, (2 ** 1) * self.features, kernel_size=(3, 3), bias=self.bias,padding=1)\n",
    "\n",
    "        self.crossgatingblock5 = CrossGatingBlock(dim=dim,dim_v=64,dim_u=64,num_channels=num_channels,features=self.features,\n",
    "                                                  block_size=self.block_size_hr if 0 < self.high_res_stages else self.block_size_lr,\n",
    "                                                  grid_size=self.grid_size_hr if 0 < self.high_res_stages else self.block_size_lr,\n",
    "                                                  input_proj_factor=self.input_proj_factor,\n",
    "                                                  dropout_rate=self.drop, upsample_y=True, use_bias=self.bias,c=1)\n",
    "\n",
    "        self.conv9 = nn.Conv2d((2 ** 0) * self.features, (2 ** 0) * self.features, kernel_size=(1, 1), bias=self.bias,padding=1)\n",
    "        self.conv10 = nn.Conv2d((2 ** 0) * self.features, (2 ** 0) * self.features, kernel_size=(3, 3), bias=self.bias,padding=1)\n",
    "\n",
    "\n",
    "        self.unsampleratio9 = UpSampleRatio(4 * self.features,ratio=2**(0),use_bias=self.bias,b=2)\n",
    "        self.unsampleratio10 = UpSampleRatio(2 * self.features,ratio=2**(-1),use_bias=self.bias,b=1)\n",
    "        self.unsampleratio11 = UpSampleRatio(1 * self.features,ratio=2**(-2),use_bias=self.bias)\n",
    "\n",
    "        self.unsampleratio12 = UpSampleRatio(4 * self.features,ratio=2**(1),use_bias=self.bias,b=3)\n",
    "        self.unsampleratio13 = UpSampleRatio(2 * self.features,ratio=2**(0),use_bias=self.bias,b=2)\n",
    "        self.unsampleratio14 = UpSampleRatio(1 * self.features,ratio=2**(-1),use_bias=self.bias,b=1)\n",
    "\n",
    "        self.unsampleratio15 = UpSampleRatio(4 * self.features,ratio=4,use_bias=self.bias,b=4)\n",
    "        self.unsampleratio16 = UpSampleRatio(2 * self.features,ratio=2,use_bias=self.bias,b=3)\n",
    "        self.unsampleratio17 = UpSampleRatio(1 * self.features,ratio=1,use_bias=self.bias,b=2)\n",
    "\n",
    "        self.unetdecoderblock1 = UNetDecoderBlock(a=0,dim=0,num_channels=4*num_channels,n1=256,n2=n2,features=(2**2) * self.features,num_groups=self.num_groups,\n",
    "            lrelu_slope=self.lrelu_slope,block_size=self.block_size_hr if 2 < self.high_res_stages else self.block_size_lr,\n",
    "                                                 grid_size=self.grid_size_hr if 2 < self.high_res_stages else self.block_size_lr,\n",
    "            block_gmlp_factor=self.block_gmlp_factor,grid_gmlp_factor=self.grid_gmlp_factor,input_proj_factor=self.input_proj_factor,\n",
    "            channels_reduction=self.channels_reduction,use_global_mlp=self.use_global_mlp,dropout_rate=self.drop,use_bias=self.bias,d =1)\n",
    "\n",
    "        self.unetdecoderblock2 = UNetDecoderBlock(a=0,dim=0,num_channels=2*num_channels,n1=128,n2=128,features=(2**1) * self.features,num_groups=self.num_groups,\n",
    "            lrelu_slope=self.lrelu_slope,block_size=self.block_size_hr if 1 < self.high_res_stages else self.block_size_lr,\n",
    "                                                 grid_size=self.grid_size_hr if 1 < self.high_res_stages else self.block_size_lr,\n",
    "            block_gmlp_factor=self.block_gmlp_factor,grid_gmlp_factor=self.grid_gmlp_factor,input_proj_factor=self.input_proj_factor,\n",
    "            channels_reduction=self.channels_reduction,use_global_mlp=self.use_global_mlp,dropout_rate=self.drop,use_bias=self.bias,d = 1,e=3)\n",
    "\n",
    "        self.unetdecoderblock3 = UNetDecoderBlock(a=0,dim=0,num_channels=num_channels,n1=64,n2=64,features=self.features,num_groups=self.num_groups,\n",
    "            lrelu_slope=self.lrelu_slope,block_size=self.block_size_hr if 0 < self.high_res_stages else self.block_size_lr,\n",
    "                                                 grid_size=self.grid_size_hr if 0 < self.high_res_stages else self.block_size_lr,\n",
    "            block_gmlp_factor=self.block_gmlp_factor,grid_gmlp_factor=self.grid_gmlp_factor,input_proj_factor=self.input_proj_factor,\n",
    "            channels_reduction=self.channels_reduction,use_global_mlp=self.use_global_mlp,dropout_rate=self.drop,use_bias=self.bias,d =1,e=3)\n",
    "\n",
    "        self.sam1 = SAM(2 ** (2)*self.features,output_channels=self.num_outputs,use_bias=self.bias)\n",
    "        self.sam2 = SAM(2 ** (1)*self.features,output_channels=self.num_outputs,use_bias=self.bias)\n",
    "        self.sam3 = SAM(2 ** (0)*self.features,output_channels=self.num_outputs,use_bias=self.bias)\n",
    "\n",
    "        self.conv11 = nn.Conv2d((2**(2))*self.features,self.num_outputs,kernel_size=(3,3), bias=self.bias,padding=1)\n",
    "        self.conv12 = nn.Conv2d((2**(1))*self.features,self.num_outputs,kernel_size=(3,3), bias=self.bias,padding=1)\n",
    "        self.conv13 = nn.Conv2d((2**(0))*self.features,self.num_outputs,kernel_size=(3,3), bias=self.bias,padding=1)\n",
    "    def forward(self, x):\n",
    "        n, h, w, c = x.shape            #bchw\n",
    "        shortcuts = []\n",
    "        shortcuts.append(x)\n",
    "        # Get multi-scale input images\n",
    "        for i in range(1, self.num_supervision_scales):\n",
    "            x = transforms.Resize(size=(n, h // (2 ** i), w // (2 ** i), c,),interpolation=transforms.InterpolationMode.NEAREST)(x)\n",
    "            shortcuts.append(x)\n",
    "\n",
    "        # store outputs from all stages and all scales\n",
    "        # Eg, [[(64, 64, 3), (128, 128, 3), (256, 256, 3)],   # Stage-1 outputs\n",
    "        #      [(64, 64, 3), (128, 128, 3), (256, 256, 3)],]  # Stage-2 outputs\n",
    "        outputs_all = []\n",
    "        sam_features, encs_prev, decs_prev = [], [], []\n",
    "        for idx_stage in range(self.num_stages):\n",
    "        # Input convolution, get multi-scale input features\n",
    "            x_scales = []\n",
    "            for i in range(self.num_supervision_scales):\n",
    "                if i == 0:\n",
    "                    x_scale = self.conv1(shortcuts[i].permute(0, 3, 1, 2))\n",
    "                    # If later stages, fuse input features with SAM features from prev stage\n",
    "                    if idx_stage > 0:\n",
    "                        # use larger blocksize at high-res stages\n",
    "                        if self.use_cross_gating:\n",
    "\n",
    "                            x_scale, _ = self.crossgatingblock1(x_scale, sam_features.pop())\n",
    "                        else:\n",
    "                            cat = torch.cat([x_scale,sam_features.pop()],dim=-1)\n",
    "                            x_scale = self.conv2(cat)\n",
    "                    x_scales.append(x_scale)\n",
    "                else:\n",
    "                    x_scale = self.conv3(x_scales[i].permute(0, 3, 1, 2))\n",
    "                    # If later stages, fuse input features with SAM features from prev stage\n",
    "                    if idx_stage > 0:\n",
    "                        # use larger blocksize at high-res stages\n",
    "                        if self.use_cross_gating:\n",
    "                            x_scale, _ = self.crossgatingblock2(x_scale, sam_features.pop())\n",
    "\n",
    "                        else:\n",
    "                            cat = torch.cat([x_scale,sam_features.pop()],dim=-1)\n",
    "                            x_scale = self.conv4(cat)\n",
    "\n",
    "                    x_scales.append(x_scale)\n",
    "\n",
    "            # start encoder blocks\n",
    "            encs = []\n",
    "            x = x_scales[0]  # First full-scale input feature\n",
    "            for i in range(self.depth):  # 0, 1, 2\n",
    "            # use larger blocksize at high-res stages, vice versa.\n",
    "                if idx_stage ==0:\n",
    "                    if i == 0:\n",
    "                        # Multi-scale input if multi-scale supervision\n",
    "                        x_scale = x_scales[i] if i < self.num_supervision_scales else None\n",
    "\n",
    "                        enc_prev = encs_prev.pop() if idx_stage > 0 else None\n",
    "                        dec_prev = decs_prev.pop() if idx_stage > 0 else None\n",
    "                        x, bridge = self.unetencoderblock00(x,skip=x_scale,enc=enc_prev,dec=dec_prev)\n",
    "                        encs.append(bridge)\n",
    "                    elif i == 1:\n",
    "                        # Multi-scale input if multi-scale supervision\n",
    "                        x_scale = x_scales[i] if i < self.num_supervision_scales else None\n",
    "\n",
    "                        enc_prev = encs_prev.pop() if idx_stage > 0 else None\n",
    "                        dec_prev = decs_prev.pop() if idx_stage > 0 else None\n",
    "                        x, bridge = self.unetencoderblock10(x, skip=x_scale, enc=enc_prev, dec=dec_prev)\n",
    "                        encs.append(bridge)\n",
    "                    else:\n",
    "                        # Multi-scale input if multi-scale supervision\n",
    "                        x_scale = x_scales[i] if i < self.num_supervision_scales else None\n",
    "\n",
    "                        enc_prev = encs_prev.pop() if idx_stage > 0 else None\n",
    "                        dec_prev = decs_prev.pop() if idx_stage > 0 else None\n",
    "                        x, bridge = self.unetencoderblock20(x, skip=x_scale, enc=enc_prev, dec=dec_prev)\n",
    "                        encs.append(bridge)\n",
    "                else:\n",
    "                    if i == 0:\n",
    "                        # Multi-scale input if multi-scale supervision\n",
    "                        x_scale = x_scales[i] if i < self.num_supervision_scales else None\n",
    "\n",
    "                        enc_prev = encs_prev.pop() if idx_stage > 0 else None\n",
    "                        dec_prev = decs_prev.pop() if idx_stage > 0 else None\n",
    "                        x, bridge = self.unetencoderblock01(x.permute(0, 3, 1, 2), skip=x_scale.permute(0, 3, 1, 2), enc=enc_prev, dec=dec_prev)\n",
    "                        encs.append(bridge)\n",
    "                    elif i == 1:\n",
    "                        # Multi-scale input if multi-scale supervision\n",
    "                        x_scale = x_scales[i] if i < self.num_supervision_scales else None\n",
    "\n",
    "                        enc_prev = encs_prev.pop() if idx_stage > 0 else None\n",
    "                        dec_prev = decs_prev.pop() if idx_stage > 0 else None\n",
    "                        x, bridge = self.unetencoderblock11(x, skip=x_scale, enc=enc_prev, dec=dec_prev)\n",
    "                        encs.append(bridge)\n",
    "                    else:\n",
    "                        # Multi-scale input if multi-scale supervision\n",
    "                        x_scale = x_scales[i] if i < self.num_supervision_scales else None\n",
    "\n",
    "                        enc_prev = encs_prev.pop() if idx_stage > 0 else None\n",
    "                        dec_prev = decs_prev.pop() if idx_stage > 0 else None\n",
    "                        x, bridge = self.unetencoderblock21(x, skip=x_scale, enc=enc_prev, dec=dec_prev)\n",
    "                        encs.append(bridge)\n",
    "\n",
    "\n",
    "            # Global MLP bottleneck blocks\n",
    "            for i in range(self.num_bottleneck_blocks):\n",
    "                x = self.bottleneckblock(x)\n",
    "\n",
    "            # cache global feature for cross-gating\n",
    "            global_feature = x\n",
    "\n",
    "            # start cross gating. Use multi-scale feature fusion\n",
    "            skip_features = []\n",
    "            if idx_stage==1:\n",
    "                for index in range(len(encs)):\n",
    "                    encs[index] = encs[index].permute(0,3,1,2)\n",
    "            for i in reversed(range(self.depth)):  # 2, 1, 0\n",
    "                if i == 2:\n",
    "                    # get multi-scale skip signals from cross-gating block\n",
    "                    signal0 = self.unsampleratio0(encs[0])\n",
    "                    signal1 = self.unsampleratio1(encs[1])\n",
    "                    signal2 = self.unsampleratio2(encs[2])\n",
    "\n",
    "                    signal = torch.cat([signal0,signal1,signal2],dim=1)\n",
    "\n",
    "                    # Use cross-gating to cross modulate features\n",
    "                    if self.use_cross_gating:\n",
    "                        skips, global_feature = self.crossgatingblock3(signal, global_feature)\n",
    "                        global_feature = global_feature.permute(0,3,1,2)\n",
    "                    else:\n",
    "                        skips = self.conv5(signal)\n",
    "                        skips = self.conv6(skips)\n",
    "                    skip_features.append(skips)\n",
    "                elif i == 1:\n",
    "                    # get multi-scale skip signals from cross-gating block\n",
    "                    signal0 = self.unsampleratio3(encs[0])\n",
    "                    signal1 = self.unsampleratio4(encs[1])\n",
    "                    signal2 = self.unsampleratio5(encs[2])\n",
    "\n",
    "                    signal = torch.cat([signal0, signal1, signal2], dim=1)\n",
    "                    # Use cross-gating to cross modulate features\n",
    "                    if self.use_cross_gating:\n",
    "                        skips, global_feature = self.crossgatingblock4(signal, global_feature)\n",
    "                    else:\n",
    "                        skips = self.conv7(signal)\n",
    "                        skips = self.conv8(skips)\n",
    "                    skip_features.append(skips)\n",
    "                elif i == 0:\n",
    "                    # get multi-scale skip signals from cross-gating block\n",
    "                    signal0 = self.unsampleratio6(encs[0])\n",
    "                    signal1 = self.unsampleratio7(encs[1])\n",
    "                    signal2 = self.unsampleratio8(encs[2])\n",
    "\n",
    "                    signal = torch.cat([signal0,signal1,signal2],dim=1)\n",
    "                    # Use cross-gating to cross modulate features\n",
    "                    if self.use_cross_gating:\n",
    "                        skips, global_feature = self.crossgatingblock5(signal, global_feature)\n",
    "                    else:\n",
    "                        skips = self.conv9(signal)\n",
    "                        skips = self.conv10(skips)\n",
    "                    skip_features.append(skips)\n",
    "\n",
    "            # for i in skip_features:\n",
    "            # start decoder. Multi-scale feature fusion of cross-gated features\n",
    "            outputs, decs, sam_features = [], [], []\n",
    "            for i in reversed(range(self.depth)):\n",
    "                if i == 2:\n",
    "                    # get multi-scale skip signals from cross-gating block\n",
    "                    signal0 = self.unsampleratio9(skip_features[0].permute(0,3,1,2))\n",
    "                    signal1 = self.unsampleratio10(skip_features[1].permute(0,3,1,2))\n",
    "                    signal2 = self.unsampleratio11(skip_features[2].permute(0,3,1,2))\n",
    "\n",
    "                    signal = torch.cat([signal0, signal1, signal2], dim=1)\n",
    "                    # Decoder block\n",
    "                    x = self.unetdecoderblock1(x, bridge=signal)\n",
    "                    decs.append(x)\n",
    "\n",
    "                elif i == 1:\n",
    "                    # get multi-scale skip signals from cross-gating block\n",
    "                    signal0 = self.unsampleratio12(skip_features[0].permute(0,3,1,2))\n",
    "                    signal1 = self.unsampleratio13(skip_features[1].permute(0,3,1,2))\n",
    "                    signal2 = self.unsampleratio14(skip_features[2].permute(0,3,1,2))\n",
    "\n",
    "                    signal = torch.cat([signal0, signal1, signal2], dim=1)\n",
    "                    # Decoder block\n",
    "                    x = self.unetdecoderblock2(x, bridge=signal)\n",
    "                    decs.append(x)\n",
    "\n",
    "                elif i == 0:\n",
    "                    # get multi-scale skip signals from cross-gating block\n",
    "                    signal0 = self.unsampleratio15(skip_features[0].permute(0,3,1,2))\n",
    "                    signal1 = self.unsampleratio16(skip_features[1].permute(0,3,1,2))\n",
    "                    signal2 = self.unsampleratio17(skip_features[2].permute(0,3,1,2))\n",
    "\n",
    "                    signal = torch.cat([signal0, signal1, signal2], dim=1)\n",
    "\n",
    "                    # Decoder block\n",
    "                    x = self.unetdecoderblock3(x, bridge=signal)\n",
    "                    decs.append(x)\n",
    "                # output conv, if not final stage, use supervised-attention-block.\n",
    "                if i < self.num_supervision_scales:\n",
    "                    if idx_stage < self.num_stages - 1:  # not last stage, apply SAM\n",
    "                        sam, output = self.sam3(x, shortcuts[i])\n",
    "                        outputs.append(output)\n",
    "                        sam_features.append(sam)\n",
    "                    else:  # Last stage, apply output convolutions\n",
    "                        output = self.conv13(x)\n",
    "                        output1 = output.permute(0,2,3,1) + shortcuts[i]\n",
    "                        outputs.append(output)\n",
    "\n",
    "            # Cache encoder and decoder features for later-stage's usage\n",
    "            encs_prev = encs[::-1]\n",
    "            decs_prev = decs\n",
    "            # Store outputs\n",
    "            outputs_all.append(outputs)\n",
    "        return output1.permute(0,3,1,2),_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MAXIM Backbone\n",
    "\n",
    "<img src=./img/MAXIMBackbone.jpeg width=30%>\n",
    "\n",
    "由上图可以看出Backbone主要由CGB、Encoder、Decoder以及Bottleneck。\n",
    "### Encoder/Decode/Bottleneck\n",
    "\n",
    "<img src=./img/Encoder.jpeg width=20%>\n",
    "\n",
    "注意Bottleneck和Encoder/Decoder的区别：Bottleneck使用的是RDCAB和Encode使用的是RCAB\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BottleneckBlock(nn.Module):\n",
    "    \"\"\"The bottleneck block consisting of multi-axis gMLP block and RDCAB.\"\"\"\n",
    "    def __init__(self,a,n1,n2,dim,num_channels,features, block_size, grid_size,num_groups=1,block_gmlp_factor=2,grid_gmlp_factor=2,input_proj_factor=2,channels_reduction=4,use_bias=True, dropout_rate=0.):\n",
    "        super().__init__()\n",
    "        self.features = features\n",
    "        self.block_size = block_size\n",
    "        self.grid_size = grid_size\n",
    "        self.num_groups = num_groups\n",
    "        self.block_gmlp_factor = block_gmlp_factor\n",
    "        self.grid_gmlp_factor = grid_gmlp_factor\n",
    "        self.input_proj_factor = input_proj_factor\n",
    "        self.channels_reduction = channels_reduction\n",
    "        self.bias = use_bias\n",
    "        self.drop = dropout_rate\n",
    "        self.conv1 = nn.Conv2d(self.features,self.features,kernel_size=(1,1),stride=1)\n",
    "        self.residualsplitheadmultiaxisgmlpLayer = ResidualSplitHeadMultiAxisGmlpLayer(n1=n1,n2=n2,dim=dim,num_channels=num_channels,grid_size=self.grid_size,block_size=self.block_size,\n",
    "                grid_gmlp_factor=self.grid_gmlp_factor,block_gmlp_factor=self.block_gmlp_factor,input_proj_factor=self.input_proj_factor,use_bias=self.bias,dropout_rate=self.drop)\n",
    "        self.rdcab = RDCAB(a=a,dim=dim,features=self.features,reduction=self.channels_reduction,use_bias=self.bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        assert x.ndim == 4  # Input has shape [batch, h, w, c]\n",
    "        # input projection\n",
    "        x = self.conv1(x)\n",
    "        shortcut_long = x\n",
    "        for i in range(self.num_groups):\n",
    "            x = self.residualsplitheadmultiaxisgmlpLayer(x)\n",
    "            # Channel-mixing part, which provides within-patch communication.\n",
    "            x = self.rdcab(x)\n",
    "        x = x + shortcut_long\n",
    "        return x\n",
    "\n",
    "\n",
    "class UNetEncoderBlock(nn.Module):\n",
    "    \"\"\"Encoder block in MAXIM.\"\"\"\n",
    "\n",
    "    def __init__(self,a,n1,n2,num_channels,dim, features, block_size, grid_size, num_groups=1, lrelu_slope=0.2,block_gmlp_factor=2, grid_gmlp_factor=2,\n",
    "                input_proj_factor=2, channels_reduction=4, dropout_rate=0., use_bias=True,downsample=True,use_global_mlp=True,use_cross_gating=False,d=0,idx=0,dim_v=64,dim_u=64,f=0,g=0):\n",
    "        super().__init__()\n",
    "        self.dim =dim\n",
    "        self.dim_v = dim_v\n",
    "        self.dim_u = dim_u\n",
    "        self.idx = idx\n",
    "        self.d = d\n",
    "        self.num_channels = num_channels\n",
    "        self.features = features\n",
    "        self.block_size = block_size\n",
    "        self.grid_size = grid_size\n",
    "        self.num_groups = num_groups\n",
    "        self.lrelu_slope = lrelu_slope\n",
    "        self.block_gmlp_factor = block_gmlp_factor\n",
    "        self.grid_gmlp_factor = grid_gmlp_factor\n",
    "        self.input_proj_factor = input_proj_factor\n",
    "        self.channels_reduction = channels_reduction\n",
    "        self.downsample = downsample\n",
    "        self.use_global_mlp = use_global_mlp\n",
    "        self.use_cross_gating = use_cross_gating\n",
    "        self.bias = use_bias\n",
    "        self.drop = dropout_rate\n",
    "        self.conv1 = nn.Conv2d(2*self.features,self.features,kernel_size=(1,1),stride=(1,1),bias=self.bias)\n",
    "        self.conv5 = nn.Conv2d(4*self.features,self.features,kernel_size=(1,1),stride=(1,1),bias=self.bias)\n",
    "        self.conv3 = nn.Conv2d(self.features,2*self.features,kernel_size=(1,1),stride=(1,1),bias=self.bias)\n",
    "        self.conv6 = nn.Conv2d(self.features,self.features,kernel_size=(1,1),stride=(1,1),bias=self.bias)\n",
    "        self.residualsplitheadmultiaxisgmlpLayer = ResidualSplitHeadMultiAxisGmlpLayer(dim=dim,n1=n1,n2=n2,num_channels=num_channels,grid_size=self.grid_size,block_size=self.block_size,\n",
    "        grid_gmlp_factor=self.grid_gmlp_factor,block_gmlp_factor=self.block_gmlp_factor,input_proj_factor=self.input_proj_factor,\n",
    "        use_bias=self.bias,dropout_rate=self.drop)\n",
    "        self.rcab = RCAB(dim=dim,features=self.features,reduction=self.channels_reduction,use_bias=self.bias,a=a)\n",
    "        self.crossgatingblock = CrossGatingBlock(dim=dim,dim_v=dim_v,dim_u=dim_u,num_channels=num_channels,features=self.features,block_size=self.block_size,grid_size=self.grid_size,\n",
    "          dropout_rate=self.drop,input_proj_factor=self.input_proj_factor,upsample_y=False,use_bias=self.bias,idx=idx,f=f,g=g)\n",
    "        self.conv2 = nn.Conv2d(self.features,self.features,kernel_size=(4,4),stride=2,padding=1)\n",
    "        self.conv7 = nn.Conv2d(self.features,self.features,kernel_size=(4,4),stride=2,padding=1)\n",
    "        self.conv4 = nn.Conv2d(2*self.features,2*self.features,kernel_size=(4,4),stride=2,padding=1)\n",
    "        self.conv8 = nn.Conv2d(2*self.features,2*self.features,kernel_size=(4,4),stride=2,padding=1)\n",
    "    def forward(self, x,skip=None,enc=None,dec=None):\n",
    "\n",
    "        if skip is not None:\n",
    "            x = torch.cat([x, skip], dim=1)\n",
    "            if self.d ==0:\n",
    "                x = self.conv1(x)\n",
    "            elif self.d == 1:\n",
    "                x = self.conv5(x)\n",
    "            elif self.d==2:\n",
    "                x = self.conv6(x)\n",
    "        else:\n",
    "            x = self.conv3(x)\n",
    "        shortcut_long = x\n",
    "        for i in range(self.num_groups):\n",
    "            if self.use_global_mlp:\n",
    "                x = self.residualsplitheadmultiaxisgmlpLayer(x)\n",
    "                x = self.rcab(x)\n",
    "                x = x + shortcut_long\n",
    "        if enc is not None and dec is not None:\n",
    "            assert self.use_cross_gating\n",
    "            x, _ = self.crossgatingblock(x,enc+dec)\n",
    "        if self.downsample and self.dim==0 and self.idx==0:\n",
    "            x_down = self.conv2(x)\n",
    "            return x_down, x\n",
    "        elif self.downsample and self.dim == 1 and self.idx==0:\n",
    "            x_down = self.conv4(x)\n",
    "            return x_down, x\n",
    "        elif self.downsample and self.dim==0 and self.idx==1:\n",
    "            x_down = self.conv7(x.permute(0,3,1,2))\n",
    "            return x_down, x\n",
    "        elif self.downsample and self.dim==1 and self.idx==1:\n",
    "            x_down = self.conv8(x.permute(0,3,1,2))\n",
    "            return x_down, x\n",
    "        else:\n",
    "            return x\n",
    "\n",
    "\n",
    "class UNetDecoderBlock(nn.Module):\n",
    "    \"\"\"Decoder block in MAXIM.\"\"\"\n",
    "    def __init__(self,a,d,dim,n1,n2,num_channels, features, block_size, grid_size, num_groups=1, lrelu_slope=0.2, block_gmlp_factor=2,\n",
    "           grid_gmlp_factor=2,\n",
    "           input_proj_factor=2, channels_reduction=4, dropout_rate=0., use_bias=True, downsample=True,\n",
    "           use_global_mlp=True,e = 0):\n",
    "        super().__init__()\n",
    "        self.e = e\n",
    "        self.features = features\n",
    "        self.block_size = block_size\n",
    "        self.grid_size = grid_size\n",
    "        self.num_groups = num_groups\n",
    "        self.lrelu_slope = lrelu_slope\n",
    "        self.block_gmlp_factor = block_gmlp_factor\n",
    "        self.grid_gmlp_factor = grid_gmlp_factor\n",
    "        self.input_proj_factor = input_proj_factor\n",
    "        self.channels_reduction = channels_reduction\n",
    "        self.downsample = downsample\n",
    "        self.use_global_mlp = use_global_mlp\n",
    "        self.bias = use_bias\n",
    "        self.drop = dropout_rate\n",
    "        self.conv1 = nn.ConvTranspose2d(self.features,self.features,kernel_size=(2,2),stride=2,bias=self.bias)\n",
    "        self.conv2 = nn.ConvTranspose2d(self.features,self.features//2,kernel_size=(2,2),stride=2,bias=self.bias)\n",
    "        self.conv3 = nn.ConvTranspose2d(self.features*2,self.features//2,kernel_size=(2,2),stride=2,bias=self.bias)\n",
    "        self.conv4 = nn.ConvTranspose2d(self.features*2,self.features,kernel_size=(2,2),stride=2,bias=self.bias)\n",
    "        self.unetencoderblock = UNetEncoderBlock(a=a,dim=dim,n1=n1,n2=n2,num_channels=num_channels,features=self.features, num_groups=self.num_groups,lrelu_slope=self.lrelu_slope,block_size=self.block_size,\n",
    "        grid_size=self.grid_size,block_gmlp_factor=self.block_gmlp_factor,grid_gmlp_factor=self.grid_gmlp_factor, channels_reduction=self.channels_reduction,\n",
    "        use_global_mlp=self.use_global_mlp,dropout_rate=self.drop,downsample=False,use_bias=self.bias,d = d)\n",
    "\n",
    "    def forward(self, x,bridge=None):\n",
    "        if self.e==0:\n",
    "            x = self.conv1(x)\n",
    "        elif self.e==1:\n",
    "            x = self.conv2(x)\n",
    "        elif self.e == 2:\n",
    "            x = self.conv3(x)\n",
    "        elif self.e == 3:\n",
    "            x = self.conv4(x)\n",
    "        x = self.unetencoderblock(x,skip=bridge)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Residual Channel Attention Block(RCAB and RDCAB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CALayer(nn.Module):\n",
    "    \"\"\"Squeeze-and-excitation block for channel attention.\n",
    "    ref: https://arxiv.org/abs/1709.01507\n",
    "    \"\"\"\n",
    "    def __init__(self,a, features, reduction=4, use_bias=True):\n",
    "        super().__init__()\n",
    "        self.features = features\n",
    "        self.reduction = reduction\n",
    "        self.bias = use_bias\n",
    "        self.a = a\n",
    "        self.conv1 = nn.Conv2d(self.features,self.features//self.reduction,kernel_size=(1,1),stride=1,bias=self.bias)\n",
    "        self.conv3 = nn.Conv2d(self.features*2,self.features//self.reduction,kernel_size=(1,1),stride=1,bias=self.bias)\n",
    "        self.conv4 = nn.Conv2d(self.features*4,self.features//self.reduction,kernel_size=(1,1),stride=1,bias=self.bias)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.conv2 = nn.Conv2d(self.features// self.reduction, self.features , kernel_size=(1, 1), stride=1, bias=self.bias)\n",
    "        self.conv5 = nn.Conv2d(self.features// self.reduction, self.features*2 , kernel_size=(1, 1), stride=1, bias=self.bias)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    def forward(self, x):\n",
    "        y = torch.mean(x,dim=(2,3),keepdim=True)\n",
    "        if self.a == 0:\n",
    "            y = self.conv1(y)\n",
    "            y = self.relu(y)\n",
    "            y = self.conv2(y)\n",
    "            y = self.sigmoid(y)\n",
    "        elif self.a == 1:\n",
    "            y = self.conv3(y)\n",
    "            y = self.relu(y)\n",
    "            y = self.conv5(y)\n",
    "            y = self.sigmoid(y)\n",
    "        else:\n",
    "            y = self.conv4(y)\n",
    "        return x * y\n",
    "class MlpBlock(nn.Module):\n",
    "    \"\"\"A 1-hidden-layer MLP block, applied over the last dimension.\"\"\"\n",
    "    def __init__(self, mlp_dim , dropout_rate=0.,use_bias=True):\n",
    "        super().__init__()\n",
    "        self.mlp_dim=mlp_dim\n",
    "        self.dropout_rate=dropout_rate\n",
    "        self.use_bias=use_bias\n",
    "        self.fc1 = nn.Linear(self.mlp_dim, self.mlp_dim,bias=self.use_bias)\n",
    "        self.gelu = nn.GELU()\n",
    "        self.dropout = nn.Dropout(self.dropout_rate)\n",
    "        self.fc2 = nn.Linear(self.mlp_dim, self.mlp_dim,bias=self.use_bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.permute(0,2,3,1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.gelu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        x = x.permute(0,3,1,2)\n",
    "        return x\n",
    "\n",
    "class RCAB(nn.Module):\n",
    "    \"\"\"Residual channel attention block. Contains LN,Conv,lRelu,Conv,SELayer.\"\"\"\n",
    "    def __init__(self,a,features,dim=0 , reduction=4, lrelu_slope=0.2, use_bias=True):\n",
    "        super().__init__()\n",
    "        self.features = features\n",
    "        self.dim = dim\n",
    "        self.reduction = reduction\n",
    "        self.lrelu_slope = lrelu_slope\n",
    "        self.bias = use_bias\n",
    "        self.layernorm = nn.LayerNorm(dim)\n",
    "        self.conv1 = nn.Conv2d(self.features,self.features,kernel_size=(3,3),stride=1,bias=self.bias,padding=1)\n",
    "        self.conv3 = nn.Conv2d(2*self.features,2*self.features,kernel_size=(3,3),stride=1,bias=self.bias,padding=1)\n",
    "        self.leakly_relu = nn.LeakyReLU(negative_slope=self.lrelu_slope)\n",
    "        self.conv2 = nn.Conv2d(self.features,self.features,kernel_size=(3,3),stride=1,bias=self.bias,padding=1)\n",
    "        self.conv4 = nn.Conv2d(2*self.features,2*self.features,kernel_size=(3,3),stride=1,bias=self.bias,padding=1)\n",
    "        self.calayer = CALayer(features=self.features,reduction=self.reduction,use_bias=self.bias,a=a)\n",
    "    def forward(self, x):\n",
    "        shortcut = x\n",
    "        x = layer_norm_process(x)\n",
    "        if self.dim == 0:\n",
    "            x = self.conv1(x)\n",
    "            x = self.leakly_relu(x)\n",
    "            x = self.conv2(x)\n",
    "        else:\n",
    "            x = self.conv3(x)\n",
    "            x = self.leakly_relu(x)\n",
    "            x = self.conv4(x)\n",
    "        x = self.calayer(x)\n",
    "        return x + shortcut\n",
    "\n",
    "class RDCAB(nn.Module):\n",
    "    \"\"\"Residual dense channel attention block. Used in Bottlenecks.\"\"\"\n",
    "    def __init__(self,a, dim,features, reduction=16, use_bias=True, dropout_rate=0.):\n",
    "        super().__init__()\n",
    "        self.features = features\n",
    "        self.reduction = reduction\n",
    "        self.bias = use_bias\n",
    "        self.drop = dropout_rate\n",
    "        self.norm = nn.LayerNorm(dim)\n",
    "        self.mlpblock = MlpBlock(mlp_dim=self.features, dropout_rate=self.drop,use_bias=self.bias)\n",
    "        self.calayer = CALayer(a=a,features=self.features,reduction=self.reduction,use_bias=self.bias)\n",
    "    def forward(self, x):\n",
    "        x = x.permute(0,2,3,1)\n",
    "        y = layer_norm_process(x)\n",
    "        y = y.permute(0, 3, 1, 2)\n",
    "        y = self.mlpblock(y)\n",
    "        y = self.calayer(y)\n",
    "        x = x.permute(0,3,1,2)\n",
    "        x = x + y\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multi-Axis Gated MLP Block\n",
    "\n",
    "<img src=./img/Multi-axis_gated_MLP.png>\n",
    "\n",
    "在global分支处，下面这张图能更好地解释全局分支\n",
    "\n",
    "<img src=./img/Gird.jpeg width=50%>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class GridGatingUnit(nn.Module):#缺n          dim                                                        n1 = x.shape[-3]    n2,\n",
    "    \"\"\"A SpatialGatingUnit as defined in the gMLP paper.\n",
    "    The 'spatial' dim is defined as the second last.\n",
    "    If applied on other dims, you should swapaxes first.\n",
    "    \"\"\"\n",
    "    def __init__(self,n1,dim,use_bias=True):\n",
    "        super().__init__()\n",
    "        self.bias = use_bias\n",
    "        self.n1 = n1\n",
    "        self.layernorm = nn.LayerNorm(dim)\n",
    "        self.fc = nn.Linear(n1,n1,bias=self.bias)\n",
    "    def forward(self, x):\n",
    "        c = x.size(-1)\n",
    "        c = c//2\n",
    "        u, v = torch.split(x, c, dim=-1)\n",
    "        v = layer_norm_process(v)\n",
    "        v = self.fc(v)\n",
    "        return u * (v + 1.)\n",
    "\n",
    "\n",
    "class GridGmlpLayer(nn.Module):\n",
    "    \"\"\"Grid gMLP layer that performs global mixing of tokens.\"\"\"\n",
    "    def __init__(self,n1, dim,grid_size,num_channels, use_bias=True,factor=2,dropout_rate=0.):\n",
    "        super().__init__()\n",
    "        self.grid_size = grid_size\n",
    "        self.num_channels = num_channels\n",
    "        self.layernorm = nn.LayerNorm(dim)\n",
    "        self.bias = use_bias\n",
    "        self.factor = factor\n",
    "        self.drop = dropout_rate\n",
    "        self.gelu = nn.GELU()\n",
    "        self.gridgatingunit = GridGatingUnit(n1,dim=dim,use_bias=self.bias)\n",
    "        self.dropout = nn.Dropout(self.drop)\n",
    "        self.fc1 = nn.Linear(num_channels,num_channels*self.factor,bias=self.bias)\n",
    "        self.fc2 = nn.Linear(num_channels,num_channels,bias=self.bias)\n",
    "    def forward(self, x):\n",
    "        n, h, w, num_channels = x.shape\n",
    "        gh, gw = self.grid_size\n",
    "        fh, fw = h // gh, w // gw\n",
    "        x = block_images_einops(x, patch_size=(fh, fw))\n",
    "        # gMLP1: Global (grid) mixing part, provides global grid communication.\n",
    "        y = layer_norm_process(x)\n",
    "        y = self.fc1(y)\n",
    "        y = self.gelu(y)\n",
    "        y = self.gridgatingunit(y)\n",
    "        y = self.fc2(y)\n",
    "        y = self.dropout(y)\n",
    "        x = x + y\n",
    "        x = unblock_images_einops(x, grid_size=(gh, gw), patch_size=(fh, fw))\n",
    "        return x\n",
    "\n",
    "\n",
    "class BlockGatingUnit(nn.Module):\n",
    "    \"\"\"A SpatialGatingUnit as defined in the gMLP paper.\n",
    "    The 'spatial' dim is defined as the **second last**.\n",
    "    If applied on other dims, you should swapaxes first.\n",
    "    \"\"\"\n",
    "    def __init__(self,n2,dim, use_bias=True):\n",
    "        super().__init__()\n",
    "        self.bias = use_bias\n",
    "        self.layernorm = nn.LayerNorm(dim)\n",
    "        self.n2=n2\n",
    "        self.fc = nn.Linear(n2,n2,bias=self.bias)\n",
    "    def forward(self, x):\n",
    "        c = x.size(-1)\n",
    "        c = c//2\n",
    "        u, v = torch.split(x, c, dim=-1)\n",
    "        v = layer_norm_process(v)\n",
    "        v = self.fc(v)\n",
    "        return u * (v + 1.)\n",
    "\n",
    "class BlockGmlpLayer(nn.Module):\n",
    "    \"\"\"Block gMLP layer that performs local mixing of tokens.\"\"\"\n",
    "    def __init__(self,n2,num_channels, block_size,dim, use_bias=True,factor=2,dropout_rate=0.):\n",
    "        super().__init__()\n",
    "        self.block_size = block_size\n",
    "        self.num_channels = num_channels\n",
    "        self.bias = use_bias\n",
    "        self.factor = factor\n",
    "        self.drop = dropout_rate\n",
    "        self.layernorm = nn.LayerNorm(dim)\n",
    "        self.gelu = nn.GELU()\n",
    "        self.dim=dim\n",
    "        self.blockgatingunit = BlockGatingUnit(n2=n2,dim=self.dim,use_bias=self.bias)\n",
    "        self.dropout = nn.Dropout(self.drop)\n",
    "        self.fc1 = nn.Linear(num_channels,num_channels * self.factor,bias=self.bias)\n",
    "        self.fc2 = nn.Linear(num_channels,num_channels,bias=self.bias)\n",
    "    def forward(self, x):\n",
    "        n, h, w, num_channels = x.shape\n",
    "        fh, fw = self.block_size\n",
    "        gh, gw = h // fh, w // fw\n",
    "        x = block_images_einops(x, patch_size=(fh, fw))\n",
    "        # MLP2: Local (block) mixing part, provides within-block communication.\n",
    "        y = layer_norm_process(x)\n",
    "        y = self.fc1(y)\n",
    "        y = self.gelu(y)\n",
    "        y = self.blockgatingunit(y)\n",
    "        y = self.fc2(y)\n",
    "        y = self.dropout(y)\n",
    "        x = x + y\n",
    "        x = unblock_images_einops(x, grid_size=(gh, gw), patch_size=(fh, fw))\n",
    "        return x\n",
    "\n",
    "class ResidualSplitHeadMultiAxisGmlpLayer(nn.Module):\n",
    "    \"\"\"The multi-axis gated MLP block.\"\"\"\n",
    "    def __init__(self, n1,n2,block_size, grid_size,dim,num_channels, block_gmlp_factor=2,grid_gmlp_factor=2 , input_proj_factor = 2,use_bias=True,dropout_rate=0.):\n",
    "        super().__init__()\n",
    "        self.block_size = block_size\n",
    "        self.grid_size = grid_size\n",
    "        self.num_channels = num_channels\n",
    "        self.block_gmlp_factor = block_gmlp_factor\n",
    "        self.grid_gmlp_factor = grid_gmlp_factor\n",
    "        self.input_proj_factor = input_proj_factor\n",
    "        self.bias = use_bias\n",
    "        self.drop = dropout_rate\n",
    "        self.fc1 = nn.Linear(num_channels,num_channels * self.input_proj_factor, bias=self.bias)\n",
    "        self.dim = dim\n",
    "        self.gelu = nn.GELU()\n",
    "        self.gridgmlplayer = GridGmlpLayer(n1=n1,dim=3,num_channels=num_channels,grid_size=self.grid_size,factor=self.grid_gmlp_factor,use_bias=self.bias, dropout_rate=self.drop)\n",
    "        self.blockgmlplayer = BlockGmlpLayer(n2=n2,dim=self.dim,num_channels=num_channels,block_size=self.block_size,factor=self.block_gmlp_factor,  use_bias=self.bias,dropout_rate=self.drop)\n",
    "        self.fc2 = nn.Linear(num_channels * self.input_proj_factor, num_channels, bias=self.bias)\n",
    "        self.dropout = nn.Dropout()\n",
    "\n",
    "    def forward(self, x):\n",
    "        shortcut = x\n",
    "        x = layer_norm_process(x.permute(0,2,3,1))\n",
    "        x = self.fc1(x)\n",
    "        x = self.gelu(x)\n",
    "        c = x.size(-1)//2\n",
    "        u, v = torch.split(x, c, dim=-1)\n",
    "        # GridGMLPLayer\n",
    "        u = self.gridgmlplayer(u)\n",
    "        # BlockGMLPLayer\n",
    "        v = self.blockgmlplayer(v)\n",
    "        x = torch.cat([u, v], dim=-1)\n",
    "        x = self.fc2(x)\n",
    "        x = x.permute(0,3,1,2)\n",
    "        x = self.dropout(x)\n",
    "        x = x + shortcut\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CGB\n",
    "\n",
    "<img src=./img/CGB.jpeg width=30%>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def layer_norm_process(feature: torch.Tensor, beta=0., gamma=1., eps=1e-5):\n",
    "    var_mean = torch.var_mean(feature, dim=-1, unbiased=False)\n",
    "\n",
    "    mean = var_mean[1]\n",
    "\n",
    "    var = var_mean[0]\n",
    "\n",
    "    # layer norm process\n",
    "    feature = (feature - mean[..., None]) / torch.sqrt(var[..., None] + eps)\n",
    "    feature = feature * gamma + beta\n",
    "\n",
    "    return feature\n",
    "\n",
    "class GetSpatialGatingWeights(nn.Module):\n",
    "    \"\"\"Get gating weights for cross-gating MLP block.\"\"\"\n",
    "\n",
    "    def __init__(self, dim,dim_u,dim_v, features,num_channels,block_size,grid_size, input_proj_factor=2, use_bias=True, dropout_rate=0.):\n",
    "        super().__init__()\n",
    "        self.dim_u = dim_u\n",
    "        self.dim_v = dim_v\n",
    "        self.features = features\n",
    "        self.num_channels = num_channels\n",
    "        self.block_size = block_size\n",
    "        self.grid_size = grid_size\n",
    "        self.bias = use_bias\n",
    "        self.drop = dropout_rate\n",
    "        self.input_proj_factor = input_proj_factor\n",
    "        self.norm = nn.LayerNorm(dim)\n",
    "        self.fc1 = nn.Linear(self.num_channels,self.num_channels*self.input_proj_factor,bias=self.bias)\n",
    "        self.gelu = nn.GELU()\n",
    "        self.fc2 = nn.Linear(int(self.num_channels*self.input_proj_factor//2),int(dim_u),bias=self.bias)\n",
    "        self.fc3 = nn.Linear(int(self.num_channels*self.input_proj_factor//2),int(dim_v),bias=self.bias)\n",
    "        self.fc4 = nn.Linear(2*self.num_channels,self.num_channels,bias=self.bias)\n",
    "        self.dropout = nn.Dropout(self.drop)\n",
    "    def forward(self, x):\n",
    "        n, h, w, num_channels = x.shape\n",
    "        # input projection\n",
    "        x = layer_norm_process(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.gelu(x)\n",
    "        c = x.size(-1)//2\n",
    "        u, v = torch.split(x, c, dim=-1)\n",
    "        # Get grid MLP weights\n",
    "        gh, gw = self.grid_size\n",
    "        fh, fw = h // gh, w // gw\n",
    "        u = block_images_einops(u, patch_size=(fh, fw))\n",
    "        u = self.fc2(u)\n",
    "        u = unblock_images_einops(u, grid_size=(gh, gw), patch_size=(fh, fw))\n",
    "        # Get Block MLP weights\n",
    "        fh, fw = self.block_size\n",
    "        gh, gw = h // fh, w // fw\n",
    "        v = block_images_einops(v, patch_size=(fh, fw))\n",
    "        v = self.fc3(v)\n",
    "        v = unblock_images_einops(v, grid_size=(gh, gw), patch_size=(fh, fw))\n",
    "        x = torch.cat([u, v], dim=-1)\n",
    "        x = self.fc4(x)\n",
    "        x = self.dropout(x)\n",
    "        return x\n",
    "        \n",
    "def block_images_einops(x, patch_size):\n",
    "    \"\"\"Image to patches.\"\"\"\n",
    "    batch, height, width, channels = x.shape\n",
    "    grid_height = height // patch_size[0]\n",
    "    grid_width = width // patch_size[1]\n",
    "    x = einops.rearrange(\n",
    "        x, \"n (gh fh) (gw fw) c -> n (gh gw) (fh fw) c\",\n",
    "        gh=grid_height, gw=grid_width, fh=patch_size[0], fw=patch_size[1])\n",
    "    return x\n",
    "\n",
    "def unblock_images_einops(x, grid_size, patch_size):\n",
    "    \"\"\"patches to images.\"\"\"\n",
    "    x = einops.rearrange(\n",
    "          x, \"n (gh gw) (fh fw) c -> n (gh fh) (gw fw) c\",\n",
    "          gh=grid_size[0], gw=grid_size[1], fh=patch_size[0], fw=patch_size[1])\n",
    "    return x\n",
    "\n",
    "class CrossGatingBlock(nn.Module):#缺dim     num_channels  n, h, w, num_channels = x.shape\n",
    "    \"\"\"Cross-gating MLP block.\"\"\"\n",
    "    def __init__(self,dim,dim_v,dim_u,features,block_size,grid_size,num_channels, input_proj_factor=2, use_bias=True,\n",
    "                 dropout_rate=0.,upsample_y=True,c=0,idx=0,f=0,g=0):\n",
    "        super().__init__()\n",
    "        self.features = features\n",
    "        self.g = g\n",
    "        self.c=c\n",
    "        self.f =f\n",
    "        self.idx=idx\n",
    "        self.block_size = block_size\n",
    "        self.num_channels = num_channels\n",
    "        self.grid_size = grid_size\n",
    "        self.bias = use_bias\n",
    "        self.drop = dropout_rate\n",
    "        self.upsample_y = upsample_y\n",
    "        self.input_proj_factor = input_proj_factor\n",
    "        self.conv1 = nn.ConvTranspose2d(self.features,self.features,kernel_size=(2,2),stride=2,bias=self.bias)\n",
    "        self.conv4 = nn.ConvTranspose2d(2*self.features,self.features,kernel_size=(2,2),stride=2,bias=self.bias)\n",
    "        self.conv2 = nn.Conv2d(3*self.features,self.features,kernel_size=(1,1),stride=1,bias=self.bias)\n",
    "        self.conv5 = nn.Conv2d(self.features,self.features,kernel_size=(1,1),stride=1,bias=self.bias)\n",
    "        self.conv6 = nn.Conv2d(2*self.features,2*self.features,kernel_size=(1,1),stride=1,bias=self.bias)\n",
    "        self.conv3 = nn.Conv2d(self.features,num_channels,kernel_size=(1,1),stride=1,bias=self.bias)\n",
    "        self.conv7 = nn.Conv2d(2*self.features,num_channels,kernel_size=(1,1),stride=1,bias=self.bias)\n",
    "        self.norm1 = nn.LayerNorm(dim)\n",
    "        self.fc1 = nn.Linear(self.features,num_channels,bias=self.bias)\n",
    "        self.fc5 = nn.Linear(2*self.features,num_channels,bias=self.bias)\n",
    "        self.gelu1 = nn.GELU()\n",
    "        self.dim = dim\n",
    "        self.getspatialgatingweights1 = GetSpatialGatingWeights(dim=dim,dim_v=dim_v,dim_u=dim_u,num_channels=num_channels,features=num_channels,block_size=self.block_size,grid_size=self.grid_size,\n",
    "            dropout_rate=self.drop,use_bias=self.bias)\n",
    "        self.norm2 = nn.LayerNorm(dim)\n",
    "        self.fc2 = nn.Linear(self.features,num_channels,bias=self.bias)\n",
    "        self.fc6 = nn.Linear(2*self.features,num_channels,bias=self.bias)\n",
    "        self.gelu2 = nn.GELU()\n",
    "        self.getspatialgatingweights2 = GetSpatialGatingWeights(dim=self.dim,dim_v=dim_v,dim_u=dim_u,num_channels=num_channels,features=num_channels,block_size=self.block_size,grid_size=self.grid_size,\n",
    "            dropout_rate=self.drop,use_bias=self.bias)\n",
    "        self.fc3 = nn.Linear(num_channels,num_channels,bias=self.bias)\n",
    "        self.dropout1 = nn.Dropout(self.drop)\n",
    "        self.fc4 = nn.Linear(num_channels,num_channels,bias=self.bias)\n",
    "        self.dropout2 = nn.Dropout(self.drop)\n",
    "    def forward(self, x,y):\n",
    "        # Upscale Y signal, y is the gating signal.\n",
    "        if self.upsample_y:\n",
    "            if self.c ==0:\n",
    "                y = self.conv1(y)\n",
    "            else:\n",
    "                y = self.conv4(y)\n",
    "        if self.idx==0:\n",
    "            x = self.conv2(x)\n",
    "        elif self.idx==1 and self.f==0:\n",
    "            x = self.conv5(x)\n",
    "        elif self.idx==1 and self.f==1:\n",
    "            x = self.conv6(x)\n",
    "        if self.f==0:\n",
    "            y = self.conv3(y)\n",
    "        elif self.f==1:\n",
    "            y = self.conv7(y)\n",
    "        assert y.shape == x.shape\n",
    "        y = y.permute(0,2,3,1)\n",
    "        x = x.permute(0,2,3,1)\n",
    "        shortcut_x = x\n",
    "        shortcut_y = y\n",
    "        # Get gating weights from X\n",
    "        x = layer_norm_process(x)\n",
    "        if self.g==0:\n",
    "            x = self.fc1(x)\n",
    "        elif self.g==1:\n",
    "            x = self.fc5(x)\n",
    "        x = self.gelu1(x)\n",
    "        gx = self.getspatialgatingweights1(x)\n",
    "        # Get gating weights from Y\n",
    "        y = layer_norm_process(y)\n",
    "        if self.g==0:\n",
    "            y = self.fc2(y)\n",
    "        elif self.g==1:\n",
    "            x = self.fc6(x)\n",
    "        y = self.gelu2(y)\n",
    "        gy = self.getspatialgatingweights2(y)\n",
    "        # Apply cross gating: X = X * GY, Y = Y * GX\n",
    "        y = y * gx\n",
    "        y = self.fc3(y)\n",
    "        y = self.dropout1(y)\n",
    "        y = y + shortcut_y\n",
    "\n",
    "        x = x * gy  # gating x using y\n",
    "        x = self.fc4(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = x + y + shortcut_x  # get all aggregated signals\n",
    "        return x, y"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9116fc67e4256ae2032cd97a5d43eaf97776cee9d03cd8e1c3e900c0daf90596"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
