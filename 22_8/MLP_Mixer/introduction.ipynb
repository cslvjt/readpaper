{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 参考\n",
    "+  https://zhuanlan.zhihu.com/p/372692759\n",
    "+  code：https://github.com/lucidrains/mlp-mixer-pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用MLP架构取得SOTA的表现"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=center>\n",
    "<img src=.\\img\\FeedForward.png width=\"20%\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, dim, hidden_dim, dropout = 0.):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(dim, hidden_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim, dim),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=center>\n",
    "<img src=.\\img\\MixerBlock.png width=\"80%\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# token-mixing\n",
    "token：图像patch的线性映射\n",
    "\n",
    "token-mixing：混合提炼不同patch的特征(不同位置的mix)\n",
    "\n",
    "token-mixing的通道混合操作类似shuffleNet的通道混洗。\n",
    "\n",
    "# channel-mixing\n",
    "channel-mixing允许不同通道之间进行交流(同一位置不同channel)\n",
    "\n",
    "独立地在每一个token操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MixerBlock(nn.Module):\n",
    "\n",
    "    def __init__(self, dim, num_patch, token_dim, channel_dim, dropout = 0.):\n",
    "        super().__init__()\n",
    "\n",
    "        #d:dim\n",
    "        #n:h*w\n",
    "        self.token_mix = nn.Sequential(\n",
    "            nn.LayerNorm(dim),\n",
    "            Rearrange('b n d -> b d n'),\n",
    "            FeedForward(num_patch, token_dim, dropout),\n",
    "            Rearrange('b d n -> b n d')\n",
    "        )\n",
    "\n",
    "        self.channel_mix = nn.Sequential(\n",
    "            nn.LayerNorm(dim),\n",
    "            FeedForward(dim, channel_dim, dropout),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = x + self.token_mix(x)\n",
    "\n",
    "        x = x + self.channel_mix(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=center>\n",
    "<img src=.\\img\\model.png width=\"80%\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPMixer(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels, dim, num_classes, patch_size, image_size, depth, token_dim, channel_dim):\n",
    "        super().__init__()\n",
    "\n",
    "        assert image_size % patch_size == 0, 'Image dimensions must be divisible by the patch size.'\n",
    "        self.num_patch =  (image_size// patch_size) ** 2\n",
    "        self.to_patch_embedding = nn.Sequential(\n",
    "            #kernel：patch_size\n",
    "            #stride：patch_size\n",
    "            nn.Conv2d(in_channels, dim, patch_size, patch_size),\n",
    "            Rearrange('b c h w -> b (h w) c'),\n",
    "        )\n",
    "\n",
    "        self.mixer_blocks = nn.ModuleList([])\n",
    "\n",
    "        for _ in range(depth):\n",
    "            self.mixer_blocks.append(MixerBlock(dim, self.num_patch, token_dim, channel_dim))\n",
    "\n",
    "        self.layer_norm = nn.LayerNorm(dim)\n",
    "\n",
    "        self.mlp_head = nn.Sequential(\n",
    "            nn.Linear(dim, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "\n",
    "        x = self.to_patch_embedding(x)\n",
    "\n",
    "        for mixer_block in self.mixer_blocks:\n",
    "            x = mixer_block(x)\n",
    "\n",
    "        x = self.layer_norm(x)\n",
    "\n",
    "        x = x.mean(dim=1)\n",
    "\n",
    "        return self.mlp_head(x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.2 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.6.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1be8e1e697be24aa51be46f7515f4d96c6005120fc689094ce96895b044c9b1b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
