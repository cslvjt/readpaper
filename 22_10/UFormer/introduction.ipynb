{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reference\n",
    "+ [official code](https://github.com/ZhendongWang6/Uformer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# question？\n",
    "## 如何理解多尺度可恢复调节器？\n",
    "<img src=./img/modulator.jpeg>\n",
    "\n",
    "a modulator is formulated as a learnable tensor with a shape ofM × M × C, where M is the window size and C is the channel dimension of current feature map. Each modulator is simply served as a shared bias term that is added into all nonoverlapping windows before self-attention module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.checkpoint as checkpoint\n",
    "from timm.models.layers import DropPath, to_2tuple, trunc_normal_\n",
    "import torch.nn.functional as F\n",
    "from einops import rearrange, repeat\n",
    "from einops.layers.torch import Rearrange\n",
    "import math\n",
    "import numpy as np\n",
    "import time\n",
    "from torch import einsum\n",
    "\n",
    "\n",
    "class FastLeFF(nn.Module):\n",
    "    \n",
    "    def __init__(self, dim=32, hidden_dim=128, act_layer=nn.GELU,drop = 0.):\n",
    "        super().__init__()\n",
    "\n",
    "        from torch_dwconv import depthwise_conv2d, DepthwiseConv2d\n",
    "\n",
    "        self.linear1 = nn.Sequential(nn.Linear(dim, hidden_dim),\n",
    "                                act_layer())\n",
    "        self.dwconv = nn.Sequential(DepthwiseConv2d(hidden_dim, hidden_dim, kernel_size=3,stride=1,padding=1),\n",
    "                        act_layer())\n",
    "        self.linear2 = nn.Sequential(nn.Linear(hidden_dim, dim))\n",
    "        self.dim = dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "    def forward(self, x):\n",
    "        # bs x hw x c\n",
    "        bs, hw, c = x.size()\n",
    "        hh = int(math.sqrt(hw))\n",
    "\n",
    "        x = self.linear1(x)\n",
    "\n",
    "        # spatial restore\n",
    "        x = rearrange(x, ' b (h w) (c) -> b c h w ', h = hh, w = hh)\n",
    "        # bs,hidden_dim,32x32\n",
    "\n",
    "        x = self.dwconv(x)\n",
    "\n",
    "        # flaten\n",
    "        x = rearrange(x, ' b c h w -> b (h w) c', h = hh, w = hh)\n",
    "\n",
    "        x = self.linear2(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def flops(self, H, W):\n",
    "        flops = 0\n",
    "        # fc1\n",
    "        flops += H*W*self.dim*self.hidden_dim \n",
    "        # dwconv\n",
    "        flops += H*W*self.hidden_dim*3*3\n",
    "        # fc2\n",
    "        flops += H*W*self.hidden_dim*self.dim\n",
    "        print(\"LeFF:{%.2f}\"%(flops/1e9))\n",
    "        return flops\n",
    "\n",
    "def conv(in_channels, out_channels, kernel_size, bias=False, stride = 1):\n",
    "    return nn.Conv2d(\n",
    "        in_channels, out_channels, kernel_size,\n",
    "        padding=(kernel_size//2), bias=bias, stride = stride)\n",
    "        \n",
    "## Supervised Attention Module\n",
    "class SAM(nn.Module):\n",
    "    def __init__(self, n_feat, kernel_size=3, bias=True):\n",
    "        super(SAM, self).__init__()\n",
    "        self.conv1 = conv(n_feat, n_feat, kernel_size, bias=bias)\n",
    "        self.conv2 = conv(n_feat, 3, kernel_size, bias=bias)\n",
    "        self.conv3 = conv(3, n_feat, kernel_size, bias=bias)\n",
    "\n",
    "    def forward(self, x, x_img):\n",
    "        x1 = self.conv1(x)\n",
    "        img = self.conv2(x) + x_img\n",
    "        x2 = torch.sigmoid(self.conv3(img))\n",
    "        x1 = x1*x2\n",
    "        x1 = x1+x\n",
    "        return x1, img\n",
    "\n",
    "\n",
    "#########################################\n",
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_channel, out_channel, strides=1):\n",
    "        super(ConvBlock, self).__init__()\n",
    "        self.strides = strides\n",
    "        self.in_channel=in_channel\n",
    "        self.out_channel=out_channel\n",
    "        self.block = nn.Sequential(\n",
    "            nn.Conv2d(in_channel, out_channel, kernel_size=3, stride=strides, padding=1),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "            nn.Conv2d(out_channel, out_channel, kernel_size=3, stride=strides, padding=1),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "        )\n",
    "        self.conv11 = nn.Conv2d(in_channel, out_channel, kernel_size=1, stride=strides, padding=0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out1 = self.block(x)\n",
    "        out2 = self.conv11(x)\n",
    "        out = out1 + out2\n",
    "        return out\n",
    "\n",
    "    def flops(self, H, W): \n",
    "        flops = H*W*self.in_channel*self.out_channel*(3*3+1)+H*W*self.out_channel*self.out_channel*3*3\n",
    "        return flops\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, block=ConvBlock,dim=32):\n",
    "        super(UNet, self).__init__()\n",
    "\n",
    "        self.dim = dim\n",
    "        self.ConvBlock1 = ConvBlock(3, dim, strides=1)\n",
    "        self.pool1 = nn.Conv2d(dim,dim,kernel_size=4, stride=2, padding=1)\n",
    "\n",
    "        self.ConvBlock2 = block(dim, dim*2, strides=1)\n",
    "        self.pool2 = nn.Conv2d(dim*2,dim*2,kernel_size=4, stride=2, padding=1)\n",
    "       \n",
    "        self.ConvBlock3 = block(dim*2, dim*4, strides=1)\n",
    "        self.pool3 = nn.Conv2d(dim*4,dim*4,kernel_size=4, stride=2, padding=1)\n",
    "       \n",
    "        self.ConvBlock4 = block(dim*4, dim*8, strides=1)\n",
    "        self.pool4 = nn.Conv2d(dim*8, dim*8,kernel_size=4, stride=2, padding=1)\n",
    "\n",
    "        self.ConvBlock5 = block(dim*8, dim*16, strides=1)\n",
    "\n",
    "        self.upv6 = nn.ConvTranspose2d(dim*16, dim*8, 2, stride=2)\n",
    "        self.ConvBlock6 = block(dim*16, dim*8, strides=1)\n",
    "\n",
    "        self.upv7 = nn.ConvTranspose2d(dim*8, dim*4, 2, stride=2)\n",
    "        self.ConvBlock7 = block(dim*8, dim*4, strides=1)\n",
    "\n",
    "        self.upv8 = nn.ConvTranspose2d(dim*4, dim*2, 2, stride=2)\n",
    "        self.ConvBlock8 = block(dim*4, dim*2, strides=1)\n",
    "\n",
    "        self.upv9 = nn.ConvTranspose2d(dim*2, dim, 2, stride=2)\n",
    "        self.ConvBlock9 = block(dim*2, dim, strides=1)\n",
    "\n",
    "        self.conv10 = nn.Conv2d(dim, 3, kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        conv1 = self.ConvBlock1(x)\n",
    "        pool1 = self.pool1(conv1)\n",
    "\n",
    "        conv2 = self.ConvBlock2(pool1)\n",
    "        pool2 = self.pool2(conv2)\n",
    "\n",
    "        conv3 = self.ConvBlock3(pool2)\n",
    "        pool3 = self.pool3(conv3)\n",
    "\n",
    "        conv4 = self.ConvBlock4(pool3)\n",
    "        pool4 = self.pool4(conv4)\n",
    "\n",
    "        conv5 = self.ConvBlock5(pool4)\n",
    "\n",
    "        up6 = self.upv6(conv5)\n",
    "        up6 = torch.cat([up6, conv4], 1)\n",
    "        conv6 = self.ConvBlock6(up6)\n",
    "\n",
    "        up7 = self.upv7(conv6)\n",
    "        up7 = torch.cat([up7, conv3], 1)\n",
    "        conv7 = self.ConvBlock7(up7)\n",
    "\n",
    "        up8 = self.upv8(conv7)\n",
    "        up8 = torch.cat([up8, conv2], 1)\n",
    "        conv8 = self.ConvBlock8(up8)\n",
    "\n",
    "        up9 = self.upv9(conv8)\n",
    "        up9 = torch.cat([up9, conv1], 1)\n",
    "        conv9 = self.ConvBlock9(up9)\n",
    "\n",
    "        conv10 = self.conv10(conv9)\n",
    "        out = x + conv10\n",
    "\n",
    "        return out\n",
    "\n",
    "    def flops(self, H, W): \n",
    "        flops = 0\n",
    "        flops += self.ConvBlock1.flops(H, W)\n",
    "        flops += H/2*W/2*self.dim*self.dim*4*4\n",
    "        flops += self.ConvBlock2.flops(H/2, W/2)\n",
    "        flops += H/4*W/4*self.dim*2*self.dim*2*4*4\n",
    "        flops += self.ConvBlock3.flops(H/4, W/4)\n",
    "        flops += H/8*W/8*self.dim*4*self.dim*4*4*4\n",
    "        flops += self.ConvBlock4.flops(H/8, W/8)\n",
    "        flops += H/16*W/16*self.dim*8*self.dim*8*4*4\n",
    "\n",
    "        flops += self.ConvBlock5.flops(H/16, W/16)\n",
    "\n",
    "        flops += H/8*W/8*self.dim*16*self.dim*8*2*2\n",
    "        flops += self.ConvBlock6.flops(H/8, W/8)\n",
    "        flops += H/4*W/4*self.dim*8*self.dim*4*2*2\n",
    "        flops += self.ConvBlock7.flops(H/4, W/4)\n",
    "        flops += H/2*W/2*self.dim*4*self.dim*2*2*2\n",
    "        flops += self.ConvBlock8.flops(H/2, W/2)\n",
    "        flops += H*W*self.dim*2*self.dim*2*2\n",
    "        flops += self.ConvBlock9.flops(H, W)\n",
    "\n",
    "        flops += H*W*self.dim*3*3*3\n",
    "        return flops\n",
    "\n",
    "\n",
    "class LPU(nn.Module):\n",
    "    \"\"\"\n",
    "    Local Perception Unit to extract local infomation.\n",
    "    LPU(X) = DWConv(X) + X\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, out_channels, stride = 1):\n",
    "        super(LPU, self).__init__()\n",
    "        self.depthwise = nn.Conv2d(in_channels, out_channels, kernel_size = 3,\n",
    "            stride = stride, padding = 1, groups = in_channels, bias = True\n",
    "        )\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "    def forward(self, x):\n",
    "        B, L, C = x.shape\n",
    "        # import pdb;pdb.set_trace()\n",
    "        H = int(math.sqrt(L))\n",
    "        W = int(math.sqrt(L))\n",
    "        x = x.transpose(1, 2).contiguous().view(B, C, H, W)\n",
    "        result = (self.depthwise(x) + x).flatten(2).transpose(1,2).contiguous()  # B H*W C\n",
    "        return result\n",
    "\n",
    "    def flops(self, H, W):\n",
    "        flops = 0\n",
    "        # conv\n",
    "        flops += H*W*self.out_channels*3*3\n",
    "        return flops\n",
    "\n",
    "#########################################\n",
    "class PosCNN(nn.Module):\n",
    "    def __init__(self, in_chans, embed_dim=768, s=1):\n",
    "        super(PosCNN, self).__init__()\n",
    "        self.proj = nn.Sequential(nn.Conv2d(in_chans, embed_dim, 3, s, 1, bias=True, groups=embed_dim))\n",
    "        self.s = s\n",
    "\n",
    "    def forward(self, x, H=None, W=None):\n",
    "        B, N, C = x.shape\n",
    "        H = H or int(math.sqrt(N))\n",
    "        W = W or int(math.sqrt(N))\n",
    "        feat_token = x\n",
    "        cnn_feat = feat_token.transpose(1, 2).view(B, C, H, W)\n",
    "        if self.s == 1:\n",
    "            x = self.proj(cnn_feat) + cnn_feat\n",
    "        else:\n",
    "            x = self.proj(cnn_feat)\n",
    "        x = x.flatten(2).transpose(1, 2)\n",
    "        return x\n",
    "\n",
    "    def no_weight_decay(self):\n",
    "        return ['proj.%d.weight' % i for i in range(4)]\n",
    "\n",
    "class SELayer(nn.Module):\n",
    "    def __init__(self, channel, reduction=16):\n",
    "        super(SELayer, self).__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool1d(1)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(channel, channel // reduction, bias=False),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(channel // reduction, channel, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, x):  # x: [B, N, C]\n",
    "        x = torch.transpose(x, 1, 2)  # [B, C, N]\n",
    "        b, c, _ = x.size()\n",
    "        y = self.avg_pool(x).view(b, c)\n",
    "        y = self.fc(y).view(b, c, 1)\n",
    "        x = x * y.expand_as(x)\n",
    "        x = torch.transpose(x, 1, 2)  # [B, N, C]\n",
    "        return x\n",
    "\n",
    "    def flops(self): \n",
    "        flops = 0\n",
    "        flops += self.channel*self.channel/self.reduction*2\n",
    "        \n",
    "        return flops\n",
    "\n",
    "class eca_layer(nn.Module):\n",
    "    \"\"\"Constructs a ECA module.\n",
    "    Args:\n",
    "        channel: Number of channels of the input feature map\n",
    "        k_size: Adaptive selection of kernel size\n",
    "    \"\"\"\n",
    "    def __init__(self, channel, k_size=3):\n",
    "        super(eca_layer, self).__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.conv = nn.Conv1d(1, 1, kernel_size=k_size, padding=(k_size - 1) // 2, bias=False) \n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.channel = channel\n",
    "        self.k_size =k_size\n",
    "\n",
    "    def forward(self, x):\n",
    "        # feature descriptor on the global spatial information\n",
    "        y = self.avg_pool(x)\n",
    "\n",
    "        # Two different branches of ECA module\n",
    "        y = self.conv(y.squeeze(-1).transpose(-1, -2)).transpose(-1, -2).unsqueeze(-1)\n",
    "\n",
    "        # Multi-scale information fusion\n",
    "        y = self.sigmoid(y)\n",
    "\n",
    "        return x * y.expand_as(x)\n",
    "\n",
    "    def flops(self): \n",
    "        flops = 0\n",
    "        flops += self.channel*self.channel*self.k_size\n",
    "        \n",
    "        return flops\n",
    "\n",
    "class eca_layer_1d(nn.Module):\n",
    "    \"\"\"Constructs a ECA module.\n",
    "    Args:\n",
    "        channel: Number of channels of the input feature map\n",
    "        k_size: Adaptive selection of kernel size\n",
    "    \"\"\"\n",
    "    def __init__(self, channel, k_size=3):\n",
    "        super(eca_layer_1d, self).__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool1d(1)\n",
    "        self.conv = nn.Conv1d(1, 1, kernel_size=k_size, padding=(k_size - 1) // 2, bias=False) \n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.channel = channel\n",
    "        self.k_size =k_size\n",
    "\n",
    "    def forward(self, x):\n",
    "        # b hw c\n",
    "        # feature descriptor on the global spatial information\n",
    "        y = self.avg_pool(x.transpose(-1, -2))\n",
    "\n",
    "        # Two different branches of ECA module\n",
    "        y = self.conv(y.transpose(-1, -2))\n",
    "\n",
    "        # Multi-scale information fusion\n",
    "        y = self.sigmoid(y)\n",
    "\n",
    "        return x * y.expand_as(x)\n",
    "\n",
    "    def flops(self): \n",
    "        flops = 0\n",
    "        flops += self.channel*self.channel*self.k_size\n",
    "        \n",
    "        return flops\n",
    "\n",
    "class SepConv2d(torch.nn.Module):\n",
    "    def __init__(self,\n",
    "                 in_channels,\n",
    "                 out_channels,\n",
    "                 kernel_size,\n",
    "                 stride=1,\n",
    "                 padding=0,\n",
    "                 dilation=1,act_layer=nn.ReLU):\n",
    "        super(SepConv2d, self).__init__()\n",
    "        self.depthwise = torch.nn.Conv2d(in_channels,\n",
    "                                         in_channels,\n",
    "                                         kernel_size=kernel_size,\n",
    "                                         stride=stride,\n",
    "                                         padding=padding,\n",
    "                                         dilation=dilation,\n",
    "                                         groups=in_channels)\n",
    "        self.pointwise = torch.nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
    "        self.act_layer = act_layer() if act_layer is not None else nn.Identity()\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.depthwise(x)\n",
    "        x = self.act_layer(x)\n",
    "        x = self.pointwise(x)\n",
    "        return x\n",
    "\n",
    "    def flops(self, HW): \n",
    "        flops = 0\n",
    "        flops += HW*self.in_channels*self.kernel_size**2/self.stride**2\n",
    "        flops += HW*self.in_channels*self.out_channels\n",
    "        print(\"SeqConv2d:{%.2f}\"%(flops/1e9))\n",
    "        return flops\n",
    "        \n",
    "######## Embedding for q,k,v ########\n",
    "class ConvProjection(nn.Module):\n",
    "    def __init__(self, dim, heads = 8, dim_head = 64, kernel_size=3, q_stride=1, k_stride=1, v_stride=1, dropout = 0.,\n",
    "                 last_stage=False,bias=True):\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        inner_dim = dim_head *  heads\n",
    "        self.heads = heads\n",
    "        pad = (kernel_size - q_stride)//2\n",
    "        self.to_q = SepConv2d(dim, inner_dim, kernel_size, q_stride, pad, bias)\n",
    "        self.to_k = SepConv2d(dim, inner_dim, kernel_size, k_stride, pad, bias)\n",
    "        self.to_v = SepConv2d(dim, inner_dim, kernel_size, v_stride, pad, bias)\n",
    "\n",
    "    def forward(self, x, attn_kv=None):\n",
    "        b, n, c, h = *x.shape, self.heads\n",
    "        l = int(math.sqrt(n))\n",
    "        w = int(math.sqrt(n))\n",
    "\n",
    "        attn_kv = x if attn_kv is None else attn_kv\n",
    "        x = rearrange(x, 'b (l w) c -> b c l w', l=l, w=w)\n",
    "        attn_kv = rearrange(attn_kv, 'b (l w) c -> b c l w', l=l, w=w)\n",
    "        # print(attn_kv)\n",
    "        q = self.to_q(x)\n",
    "        q = rearrange(q, 'b (h d) l w -> b h (l w) d', h=h)\n",
    "        \n",
    "        k = self.to_k(attn_kv)\n",
    "        v = self.to_v(attn_kv)\n",
    "        k = rearrange(k, 'b (h d) l w -> b h (l w) d', h=h)\n",
    "        v = rearrange(v, 'b (h d) l w -> b h (l w) d', h=h)\n",
    "        return q,k,v    \n",
    "    \n",
    "    def flops(self, q_L, kv_L=None): \n",
    "        kv_L = kv_L or q_L\n",
    "        flops = 0\n",
    "        flops += self.to_q.flops(q_L)\n",
    "        flops += self.to_k.flops(kv_L)\n",
    "        flops += self.to_v.flops(kv_L)\n",
    "        return flops\n",
    "\n",
    "\n",
    "class LinearProjection(nn.Module):\n",
    "    def __init__(self, dim, heads = 8, dim_head = 64, dropout = 0., bias=True):\n",
    "        super().__init__()\n",
    "        inner_dim = dim_head *  heads\n",
    "        self.heads = heads\n",
    "        self.to_q = nn.Linear(dim, inner_dim, bias = bias)\n",
    "        self.to_kv = nn.Linear(dim, inner_dim * 2, bias = bias)\n",
    "        self.dim = dim\n",
    "        self.inner_dim = inner_dim\n",
    "\n",
    "    def forward(self, x, attn_kv=None):\n",
    "        B_, N, C = x.shape\n",
    "        if attn_kv is not None:\n",
    "            attn_kv = attn_kv.unsqueeze(0).repeat(B_,1,1)\n",
    "        else:\n",
    "            attn_kv = x\n",
    "        N_kv = attn_kv.size(1)\n",
    "        q = self.to_q(x).reshape(B_, N, 1, self.heads, C // self.heads).permute(2, 0, 3, 1, 4)\n",
    "        kv = self.to_kv(attn_kv).reshape(B_, N_kv, 2, self.heads, C // self.heads).permute(2, 0, 3, 1, 4)\n",
    "        q = q[0]\n",
    "        k, v = kv[0], kv[1] \n",
    "        return q,k,v\n",
    "\n",
    "    def flops(self, q_L, kv_L=None): \n",
    "        kv_L = kv_L or q_L\n",
    "        flops = q_L*self.dim*self.inner_dim+kv_L*self.dim*self.inner_dim*2\n",
    "        return flops \n",
    "\n",
    "\n",
    "#########################################\n",
    "########### window-based self-attention #############\n",
    "class WindowAttention(nn.Module):\n",
    "    def __init__(self, dim, win_size,num_heads, token_projection='linear', qkv_bias=True, qk_scale=None, attn_drop=0., proj_drop=0.):\n",
    "\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "        self.win_size = win_size  # Wh, Ww\n",
    "        self.num_heads = num_heads\n",
    "        head_dim = dim // num_heads\n",
    "        self.scale = qk_scale or head_dim ** -0.5\n",
    "\n",
    "        # define a parameter table of relative position bias\n",
    "        self.relative_position_bias_table = nn.Parameter(\n",
    "            torch.zeros((2 * win_size[0] - 1) * (2 * win_size[1] - 1), num_heads))  # 2*Wh-1 * 2*Ww-1, nH\n",
    "\n",
    "        # get pair-wise relative position index for each token inside the window\n",
    "        coords_h = torch.arange(self.win_size[0]) # [0,...,Wh-1]\n",
    "        coords_w = torch.arange(self.win_size[1]) # [0,...,Ww-1]\n",
    "        coords = torch.stack(torch.meshgrid([coords_h, coords_w]))  # 2, Wh, Ww\n",
    "        coords_flatten = torch.flatten(coords, 1)  # 2, Wh*Ww\n",
    "        relative_coords = coords_flatten[:, :, None] - coords_flatten[:, None, :]  # 2, Wh*Ww, Wh*Ww\n",
    "        relative_coords = relative_coords.permute(1, 2, 0).contiguous()  # Wh*Ww, Wh*Ww, 2\n",
    "        relative_coords[:, :, 0] += self.win_size[0] - 1  # shift to start from 0\n",
    "        relative_coords[:, :, 1] += self.win_size[1] - 1\n",
    "        relative_coords[:, :, 0] *= 2 * self.win_size[1] - 1\n",
    "        relative_position_index = relative_coords.sum(-1)  # Wh*Ww, Wh*Ww\n",
    "        self.register_buffer(\"relative_position_index\", relative_position_index)\n",
    "        trunc_normal_(self.relative_position_bias_table, std=.02)\n",
    "            \n",
    "        if token_projection =='conv':\n",
    "            self.qkv = ConvProjection(dim,num_heads,dim//num_heads,bias=qkv_bias)\n",
    "        elif token_projection =='linear':\n",
    "            self.qkv = LinearProjection(dim,num_heads,dim//num_heads,bias=qkv_bias)\n",
    "        else:\n",
    "            raise Exception(\"Projection error!\") \n",
    "        \n",
    "        self.token_projection = token_projection\n",
    "        self.attn_drop = nn.Dropout(attn_drop)\n",
    "        self.proj = nn.Linear(dim, dim)\n",
    "        self.proj_drop = nn.Dropout(proj_drop)\n",
    "\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "\n",
    "    def forward(self, x, attn_kv=None, mask=None):\n",
    "        B_, N, C = x.shape\n",
    "        q, k, v = self.qkv(x,attn_kv)\n",
    "        q = q * self.scale\n",
    "        attn = (q @ k.transpose(-2, -1))\n",
    "\n",
    "        relative_position_bias = self.relative_position_bias_table[self.relative_position_index.view(-1)].view(\n",
    "            self.win_size[0] * self.win_size[1], self.win_size[0] * self.win_size[1], -1)  # Wh*Ww,Wh*Ww,nH\n",
    "        relative_position_bias = relative_position_bias.permute(2, 0, 1).contiguous()  # nH, Wh*Ww, Wh*Ww\n",
    "        ratio = attn.size(-1)//relative_position_bias.size(-1)\n",
    "        relative_position_bias = repeat(relative_position_bias, 'nH l c -> nH l (c d)', d = ratio)\n",
    "    \n",
    "        attn = attn + relative_position_bias.unsqueeze(0)\n",
    "\n",
    "        if mask is not None:\n",
    "            nW = mask.shape[0]\n",
    "            mask = repeat(mask, 'nW m n -> nW m (n d)',d = ratio)\n",
    "            attn = attn.view(B_ // nW, nW, self.num_heads, N, N*ratio) + mask.unsqueeze(1).unsqueeze(0)\n",
    "            attn = attn.view(-1, self.num_heads, N, N*ratio)\n",
    "            attn = self.softmax(attn)\n",
    "        else:\n",
    "            attn = self.softmax(attn)\n",
    "\n",
    "        attn = self.attn_drop(attn)\n",
    "\n",
    "        x = (attn @ v).transpose(1, 2).reshape(B_, N, C)\n",
    "        x = self.proj(x)\n",
    "        x = self.proj_drop(x)\n",
    "        return x\n",
    "\n",
    "    def extra_repr(self) -> str:\n",
    "        return f'dim={self.dim}, win_size={self.win_size}, num_heads={self.num_heads}'\n",
    "\n",
    "    def flops(self, H, W):\n",
    "        # calculate flops for 1 window with token length of N\n",
    "        # print(N, self.dim)\n",
    "        flops = 0\n",
    "        N = self.win_size[0]*self.win_size[1]\n",
    "        nW = H*W/N\n",
    "        # qkv = self.qkv(x)\n",
    "        # flops += N * self.dim * 3 * self.dim\n",
    "        flops += self.qkv.flops(H*W, H*W)\n",
    "        \n",
    "        # attn = (q @ k.transpose(-2, -1))\n",
    "\n",
    "        flops += nW * self.num_heads * N * (self.dim // self.num_heads) * N\n",
    "        #  x = (attn @ v)\n",
    "        flops += nW * self.num_heads * N * N * (self.dim // self.num_heads)\n",
    "        \n",
    "        # x = self.proj(x)\n",
    "        flops += nW * N * self.dim * self.dim\n",
    "        print(\"W-MSA:{%.2f}\"%(flops/1e9))\n",
    "        return flops\n",
    "\n",
    "########### self-attention #############\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, dim,num_heads, token_projection='linear', qkv_bias=True, qk_scale=None, attn_drop=0., proj_drop=0.):\n",
    "\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "        self.num_heads = num_heads\n",
    "        head_dim = dim // num_heads\n",
    "        self.scale = qk_scale or head_dim ** -0.5\n",
    "            \n",
    "        self.qkv = LinearProjection(dim,num_heads,dim//num_heads,bias=qkv_bias)\n",
    "        \n",
    "        self.token_projection = token_projection\n",
    "        self.attn_drop = nn.Dropout(attn_drop)\n",
    "        self.proj = nn.Linear(dim, dim)\n",
    "        self.proj_drop = nn.Dropout(proj_drop)\n",
    "\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "\n",
    "    def forward(self, x, attn_kv=None, mask=None):\n",
    "        B_, N, C = x.shape\n",
    "        q, k, v = self.qkv(x,attn_kv)\n",
    "        q = q * self.scale\n",
    "        attn = (q @ k.transpose(-2, -1))\n",
    "\n",
    "        # relative_position_bias = self.relative_position_bias_table[self.relative_position_index.view(-1)].view(\n",
    "        #     self.win_size[0] * self.win_size[1], self.win_size[0] * self.win_size[1], -1)  # Wh*Ww,Wh*Ww,nH\n",
    "        # relative_position_bias = relative_position_bias.permute(2, 0, 1).contiguous()  # nH, Wh*Ww, Wh*Ww\n",
    "        # ratio = attn.size(-1)//relative_position_bias.size(-1)\n",
    "        # relative_position_bias = repeat(relative_position_bias, 'nH l c -> nH l (c d)', d = ratio)\n",
    "    \n",
    "        # attn = attn + relative_position_bias.unsqueeze(0)\n",
    "\n",
    "        if mask is not None:\n",
    "            nW = mask.shape[0]\n",
    "            # mask = repeat(mask, 'nW m n -> nW m (n d)',d = ratio)\n",
    "            attn = attn.view(B_ // nW, nW, self.num_heads, N, N) + mask.unsqueeze(1).unsqueeze(0)\n",
    "            attn = attn.view(-1, self.num_heads, N, N)\n",
    "            attn = self.softmax(attn)\n",
    "        else:\n",
    "            attn = self.softmax(attn)\n",
    "\n",
    "        attn = self.attn_drop(attn)\n",
    "\n",
    "        x = (attn @ v).transpose(1, 2).reshape(B_, N, C)\n",
    "        x = self.proj(x)\n",
    "        x = self.proj_drop(x)\n",
    "        return x\n",
    "\n",
    "    def extra_repr(self) -> str:\n",
    "        return f'dim={self.dim}, num_heads={self.num_heads}'\n",
    "\n",
    "    def flops(self, q_num, kv_num):\n",
    "        # calculate flops for 1 window with token length of N\n",
    "        # print(N, self.dim)\n",
    "        flops = 0\n",
    "        # N = self.win_size[0]*self.win_size[1]\n",
    "        # nW = H*W/N\n",
    "        # qkv = self.qkv(x)\n",
    "        # flops += N * self.dim * 3 * self.dim\n",
    "        flops += self.qkv.flops(q_num, kv_num)\n",
    "        # attn = (q @ k.transpose(-2, -1))\n",
    "\n",
    "        flops += self.num_heads * q_num * (self.dim // self.num_heads) * kv_num\n",
    "        #  x = (attn @ v)\n",
    "        flops += self.num_heads * q_num * (self.dim // self.num_heads) * kv_num\n",
    "        \n",
    "        # x = self.proj(x)\n",
    "        flops += q_num * self.dim * self.dim\n",
    "        print(\"MCA:{%.2f}\"%(flops/1e9))\n",
    "        return flops\n",
    "\n",
    "\n",
    "#########################################\n",
    "########### feed-forward network #############\n",
    "class Mlp(nn.Module):\n",
    "    def __init__(self, in_features, hidden_features=None, out_features=None, act_layer=nn.GELU, drop=0.):\n",
    "        super().__init__()\n",
    "        out_features = out_features or in_features\n",
    "        hidden_features = hidden_features or in_features\n",
    "        self.fc1 = nn.Linear(in_features, hidden_features)\n",
    "        self.act = act_layer()\n",
    "        self.fc2 = nn.Linear(hidden_features, out_features)\n",
    "        self.drop = nn.Dropout(drop)\n",
    "        self.in_features = in_features\n",
    "        self.hidden_features = hidden_features\n",
    "        self.out_features = out_features\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.act(x)\n",
    "        x = self.drop(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.drop(x)\n",
    "        return x\n",
    "\n",
    "    def flops(self, H, W):\n",
    "        flops = 0\n",
    "        # fc1\n",
    "        flops += H*W*self.in_features*self.hidden_features \n",
    "        # fc2\n",
    "        flops += H*W*self.hidden_features*self.out_features\n",
    "        print(\"MLP:{%.2f}\"%(flops/1e9))\n",
    "        return flops\n",
    "\n",
    "\n",
    "class LeFF(nn.Module):\n",
    "    def __init__(self, dim=32, hidden_dim=128, act_layer=nn.GELU,drop = 0., use_eca=False):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Sequential(nn.Linear(dim, hidden_dim),\n",
    "                                act_layer())\n",
    "        self.dwconv = nn.Sequential(nn.Conv2d(hidden_dim,hidden_dim,groups=hidden_dim,kernel_size=3,stride=1,padding=1),\n",
    "                        act_layer())\n",
    "        self.linear2 = nn.Sequential(nn.Linear(hidden_dim, dim))\n",
    "        self.dim = dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.eca = eca_layer_1d(dim) if use_eca else nn.Identity()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # bs x hw x c\n",
    "        bs, hw, c = x.size()\n",
    "        hh = int(math.sqrt(hw))\n",
    "\n",
    "        x = self.linear1(x)\n",
    "\n",
    "        # spatial restore\n",
    "        x = rearrange(x, ' b (h w) (c) -> b c h w ', h = hh, w = hh)\n",
    "        # bs,hidden_dim,32x32\n",
    "\n",
    "        x = self.dwconv(x)\n",
    "\n",
    "        # flaten\n",
    "        x = rearrange(x, ' b c h w -> b (h w) c', h = hh, w = hh)\n",
    "\n",
    "        x = self.linear2(x)\n",
    "        x = self.eca(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def flops(self, H, W):\n",
    "        flops = 0\n",
    "        # fc1\n",
    "        flops += H*W*self.dim*self.hidden_dim \n",
    "        # dwconv\n",
    "        flops += H*W*self.hidden_dim*3*3\n",
    "        # fc2\n",
    "        flops += H*W*self.hidden_dim*self.dim\n",
    "        print(\"LeFF:{%.2f}\"%(flops/1e9))\n",
    "        # eca \n",
    "        if hasattr(self.eca, 'flops'): \n",
    "            flops += self.eca.flops()\n",
    "        return flops\n",
    "\n",
    "\n",
    "\n",
    "#########################################\n",
    "# Downsample Block\n",
    "class Downsample(nn.Module):\n",
    "    def __init__(self, in_channel, out_channel):\n",
    "        super(Downsample, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channel, out_channel, kernel_size=4, stride=2, padding=1),\n",
    "        )\n",
    "        self.in_channel = in_channel\n",
    "        self.out_channel = out_channel\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, L, C = x.shape\n",
    "        # import pdb;pdb.set_trace()\n",
    "        H = int(math.sqrt(L))\n",
    "        W = int(math.sqrt(L))\n",
    "        x = x.transpose(1, 2).contiguous().view(B, C, H, W)\n",
    "        out = self.conv(x).flatten(2).transpose(1,2).contiguous()  # B H*W C\n",
    "        return out\n",
    "\n",
    "    def flops(self, H, W):\n",
    "        flops = 0\n",
    "        # conv\n",
    "        flops += H/2*W/2*self.in_channel*self.out_channel*4*4\n",
    "        print(\"Downsample:{%.2f}\"%(flops/1e9))\n",
    "        return flops\n",
    "\n",
    "# Upsample Block\n",
    "class Upsample(nn.Module):\n",
    "    def __init__(self, in_channel, out_channel):\n",
    "        super(Upsample, self).__init__()\n",
    "        self.deconv = nn.Sequential(\n",
    "            nn.ConvTranspose2d(in_channel, out_channel, kernel_size=2, stride=2),\n",
    "        )\n",
    "        self.in_channel = in_channel\n",
    "        self.out_channel = out_channel\n",
    "        \n",
    "    def forward(self, x):\n",
    "        B, L, C = x.shape\n",
    "        H = int(math.sqrt(L))\n",
    "        W = int(math.sqrt(L))\n",
    "        x = x.transpose(1, 2).contiguous().view(B, C, H, W)\n",
    "        out = self.deconv(x).flatten(2).transpose(1,2).contiguous() # B H*W C\n",
    "        return out\n",
    "\n",
    "    def flops(self, H, W):\n",
    "        flops = 0\n",
    "        # conv\n",
    "        flops += H*2*W*2*self.in_channel*self.out_channel*2*2 \n",
    "        print(\"Upsample:{%.2f}\"%(flops/1e9))\n",
    "        return flops\n",
    "\n",
    "# Input Projection\n",
    "class InputProj(nn.Module):\n",
    "    def __init__(self, in_channel=3, out_channel=64, kernel_size=3, stride=1, norm_layer=None,act_layer=nn.LeakyReLU):\n",
    "        super().__init__()\n",
    "        self.proj = nn.Sequential(\n",
    "            nn.Conv2d(in_channel, out_channel, kernel_size=3, stride=stride, padding=kernel_size//2),\n",
    "            act_layer(inplace=True)\n",
    "        )\n",
    "        if norm_layer is not None:\n",
    "            self.norm = norm_layer(out_channel)\n",
    "        else:\n",
    "            self.norm = None\n",
    "        self.in_channel = in_channel\n",
    "        self.out_channel = out_channel\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, C, H, W = x.shape\n",
    "        x = self.proj(x).flatten(2).transpose(1, 2).contiguous()  # B H*W C\n",
    "        if self.norm is not None:\n",
    "            x = self.norm(x)\n",
    "        return x\n",
    "\n",
    "    def flops(self, H, W):\n",
    "        flops = 0\n",
    "        # conv\n",
    "        flops += H*W*self.in_channel*self.out_channel*3*3\n",
    "\n",
    "        if self.norm is not None:\n",
    "            flops += H*W*self.out_channel \n",
    "        print(\"Input_proj:{%.2f}\"%(flops/1e9))\n",
    "        return flops\n",
    "\n",
    "# Output Projection\n",
    "class OutputProj(nn.Module):\n",
    "    def __init__(self, in_channel=64, out_channel=3, kernel_size=3, stride=1, norm_layer=None,act_layer=None):\n",
    "        super().__init__()\n",
    "        self.proj = nn.Sequential(\n",
    "            nn.Conv2d(in_channel, out_channel, kernel_size=3, stride=stride, padding=kernel_size//2),\n",
    "        )\n",
    "        if act_layer is not None:\n",
    "            self.proj.add_module(act_layer(inplace=True))\n",
    "        if norm_layer is not None:\n",
    "            self.norm = norm_layer(out_channel)\n",
    "        else:\n",
    "            self.norm = None\n",
    "        self.in_channel = in_channel\n",
    "        self.out_channel = out_channel\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, L, C = x.shape\n",
    "        H = int(math.sqrt(L))\n",
    "        W = int(math.sqrt(L))\n",
    "        x = x.transpose(1, 2).view(B, C, H, W)\n",
    "        x = self.proj(x)\n",
    "        if self.norm is not None:\n",
    "            x = self.norm(x)\n",
    "        return x\n",
    "\n",
    "    def flops(self, H, W):\n",
    "        flops = 0\n",
    "        # conv\n",
    "        flops += H*W*self.in_channel*self.out_channel*3*3\n",
    "\n",
    "        if self.norm is not None:\n",
    "            flops += H*W*self.out_channel \n",
    "        print(\"Output_proj:{%.2f}\"%(flops/1e9))\n",
    "        return flops\n",
    "\n",
    "#########################################\n",
    "########### window operation#############\n",
    "def window_partition(x, win_size, dilation_rate=1):\n",
    "    B, H, W, C = x.shape\n",
    "    if dilation_rate !=1:\n",
    "        x = x.permute(0,3,1,2) # B, C, H, W\n",
    "        assert type(dilation_rate) is int, 'dilation_rate should be a int'\n",
    "        x = F.unfold(x, kernel_size=win_size,dilation=dilation_rate,padding=4*(dilation_rate-1),stride=win_size) # B, C*Wh*Ww, H/Wh*W/Ww\n",
    "        windows = x.permute(0,2,1).contiguous().view(-1, C, win_size, win_size) # B' ,C ,Wh ,Ww\n",
    "        windows = windows.permute(0,2,3,1).contiguous() # B' ,Wh ,Ww ,C\n",
    "    else:\n",
    "        x = x.view(B, H // win_size, win_size, W // win_size, win_size, C)\n",
    "        windows = x.permute(0, 1, 3, 2, 4, 5).contiguous().view(-1, win_size, win_size, C) # B' ,Wh ,Ww ,C\n",
    "    return windows\n",
    "\n",
    "def window_reverse(windows, win_size, H, W, dilation_rate=1):\n",
    "    # B' ,Wh ,Ww ,C\n",
    "    B = int(windows.shape[0] / (H * W / win_size / win_size))\n",
    "    x = windows.view(B, H // win_size, W // win_size, win_size, win_size, -1)\n",
    "    if dilation_rate !=1:\n",
    "        x = windows.permute(0,5,3,4,1,2).contiguous() # B, C*Wh*Ww, H/Wh*W/Ww\n",
    "        x = F.fold(x, (H, W), kernel_size=win_size, dilation=dilation_rate, padding=4*(dilation_rate-1),stride=win_size)\n",
    "    else:\n",
    "        x = x.permute(0, 1, 3, 2, 4, 5).contiguous().view(B, H, W, -1)\n",
    "    return x\n",
    "#########################################\n",
    "########### LeWinTransformer #############\n",
    "class LeWinTransformerBlock(nn.Module):\n",
    "    def __init__(self, dim, input_resolution, num_heads, win_size=8, shift_size=0,\n",
    "                 mlp_ratio=4., qkv_bias=True, qk_scale=None, drop=0., attn_drop=0., drop_path=0.,\n",
    "                 act_layer=nn.GELU, norm_layer=nn.LayerNorm,token_projection='linear',token_mlp='leff',\n",
    "                 modulator=False,cross_modulator=False):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "        self.input_resolution = input_resolution\n",
    "        self.num_heads = num_heads\n",
    "        self.win_size = win_size\n",
    "        self.shift_size = shift_size\n",
    "        self.mlp_ratio = mlp_ratio\n",
    "        self.token_mlp = token_mlp\n",
    "        if min(self.input_resolution) <= self.win_size:\n",
    "            self.shift_size = 0\n",
    "            self.win_size = min(self.input_resolution)\n",
    "        assert 0 <= self.shift_size < self.win_size, \"shift_size must in 0-win_size\"\n",
    "\n",
    "        if modulator:\n",
    "            self.modulator = nn.Embedding(win_size*win_size, dim) # modulator\n",
    "        else:\n",
    "            self.modulator = None\n",
    "\n",
    "        if cross_modulator:\n",
    "            self.cross_modulator = nn.Embedding(win_size*win_size, dim) # cross_modulator\n",
    "            self.cross_attn = Attention(dim,num_heads,qkv_bias=qkv_bias, qk_scale=qk_scale, attn_drop=attn_drop, proj_drop=drop,\n",
    "                    token_projection=token_projection,)\n",
    "            self.norm_cross = norm_layer(dim)\n",
    "        else:\n",
    "            self.cross_modulator = None\n",
    "\n",
    "        self.norm1 = norm_layer(dim)\n",
    "        self.attn = WindowAttention(\n",
    "            dim, win_size=to_2tuple(self.win_size), num_heads=num_heads,\n",
    "            qkv_bias=qkv_bias, qk_scale=qk_scale, attn_drop=attn_drop, proj_drop=drop,\n",
    "            token_projection=token_projection)\n",
    "\n",
    "        self.drop_path = DropPath(drop_path) if drop_path > 0. else nn.Identity()\n",
    "        self.norm2 = norm_layer(dim)\n",
    "        mlp_hidden_dim = int(dim * mlp_ratio)\n",
    "        if token_mlp in ['ffn','mlp']:\n",
    "            self.mlp = Mlp(in_features=dim, hidden_features=mlp_hidden_dim,act_layer=act_layer, drop=drop) \n",
    "        elif token_mlp=='leff':\n",
    "            self.mlp =  LeFF(dim,mlp_hidden_dim,act_layer=act_layer, drop=drop)\n",
    "        \n",
    "        elif token_mlp=='fastleff':\n",
    "            self.mlp =  FastLeFF(dim,mlp_hidden_dim,act_layer=act_layer, drop=drop)    \n",
    "        else:\n",
    "            raise Exception(\"FFN error!\") \n",
    "\n",
    "\n",
    "    def with_pos_embed(self, tensor, pos):\n",
    "        return tensor if pos is None else tensor + pos\n",
    "        \n",
    "    def extra_repr(self) -> str:\n",
    "        return f\"dim={self.dim}, input_resolution={self.input_resolution}, num_heads={self.num_heads}, \" \\\n",
    "               f\"win_size={self.win_size}, shift_size={self.shift_size}, mlp_ratio={self.mlp_ratio},modulator={self.modulator}\"\n",
    "\n",
    "    def forward(self, x, mask=None):\n",
    "        B, L, C = x.shape\n",
    "        H = int(math.sqrt(L))\n",
    "        W = int(math.sqrt(L))\n",
    "        \n",
    "        ## input mask\n",
    "        if mask != None:\n",
    "            input_mask = F.interpolate(mask, size=(H,W)).permute(0,2,3,1)\n",
    "            input_mask_windows = window_partition(input_mask, self.win_size) # nW, win_size, win_size, 1\n",
    "            attn_mask = input_mask_windows.view(-1, self.win_size * self.win_size) # nW, win_size*win_size\n",
    "            attn_mask = attn_mask.unsqueeze(2)*attn_mask.unsqueeze(1) # nW, win_size*win_size, win_size*win_size\n",
    "            attn_mask = attn_mask.masked_fill(attn_mask!=0, float(-100.0)).masked_fill(attn_mask == 0, float(0.0))\n",
    "        else:\n",
    "            attn_mask = None\n",
    "\n",
    "        ## shift mask\n",
    "        if self.shift_size > 0:\n",
    "            # calculate attention mask for SW-MSA\n",
    "            shift_mask = torch.zeros((1, H, W, 1)).type_as(x)\n",
    "            h_slices = (slice(0, -self.win_size),\n",
    "                        slice(-self.win_size, -self.shift_size),\n",
    "                        slice(-self.shift_size, None))\n",
    "            w_slices = (slice(0, -self.win_size),\n",
    "                        slice(-self.win_size, -self.shift_size),\n",
    "                        slice(-self.shift_size, None))\n",
    "            cnt = 0\n",
    "            for h in h_slices:\n",
    "                for w in w_slices:\n",
    "                    shift_mask[:, h, w, :] = cnt\n",
    "                    cnt += 1\n",
    "            shift_mask_windows = window_partition(shift_mask, self.win_size)  # nW, win_size, win_size, 1\n",
    "            shift_mask_windows = shift_mask_windows.view(-1, self.win_size * self.win_size) # nW, win_size*win_size\n",
    "            shift_attn_mask = shift_mask_windows.unsqueeze(1) - shift_mask_windows.unsqueeze(2) # nW, win_size*win_size, win_size*win_size\n",
    "            shift_attn_mask = shift_attn_mask.masked_fill(shift_attn_mask != 0, float(-100.0)).masked_fill(shift_attn_mask == 0, float(0.0))\n",
    "            attn_mask = attn_mask + shift_attn_mask if attn_mask is not None else shift_attn_mask\n",
    "\n",
    "\n",
    "        if self.cross_modulator is not None:\n",
    "            shortcut = x\n",
    "            x_cross = self.norm_cross(x)\n",
    "            x_cross = self.cross_attn(x, self.cross_modulator.weight)\n",
    "            x = shortcut + x_cross\n",
    "    \n",
    "        shortcut = x\n",
    "        x = self.norm1(x)\n",
    "        x = x.view(B, H, W, C)\n",
    "\n",
    "        # cyclic shift\n",
    "        if self.shift_size > 0:\n",
    "            shifted_x = torch.roll(x, shifts=(-self.shift_size, -self.shift_size), dims=(1, 2))\n",
    "        else:\n",
    "            shifted_x = x\n",
    "\n",
    "        # partition windows\n",
    "        x_windows = window_partition(shifted_x, self.win_size)  # nW*B, win_size, win_size, C  N*C->C\n",
    "        x_windows = x_windows.view(-1, self.win_size * self.win_size, C)  # nW*B, win_size*win_size, C\n",
    "\n",
    "        # with_modulator\n",
    "        if self.modulator is not None:\n",
    "            wmsa_in = self.with_pos_embed(x_windows,self.modulator.weight)\n",
    "        else:\n",
    "            wmsa_in = x_windows\n",
    "\n",
    "        # W-MSA/SW-MSA\n",
    "        attn_windows = self.attn(wmsa_in, mask=attn_mask)  # nW*B, win_size*win_size, C\n",
    "\n",
    "        # merge windows\n",
    "        attn_windows = attn_windows.view(-1, self.win_size, self.win_size, C)\n",
    "        shifted_x = window_reverse(attn_windows, self.win_size, H, W)  # B H' W' C\n",
    "\n",
    "        # reverse cyclic shift\n",
    "        if self.shift_size > 0:\n",
    "            x = torch.roll(shifted_x, shifts=(self.shift_size, self.shift_size), dims=(1, 2))\n",
    "        else:\n",
    "            x = shifted_x\n",
    "        x = x.view(B, H * W, C)\n",
    "\n",
    "        # FFN\n",
    "        x = shortcut + self.drop_path(x)\n",
    "        x = x + self.drop_path(self.mlp(self.norm2(x)))\n",
    "        del attn_mask\n",
    "        return x\n",
    "\n",
    "    def flops(self):\n",
    "        flops = 0\n",
    "        H, W = self.input_resolution\n",
    "\n",
    "        if self.cross_modulator is not None:\n",
    "            flops += self.dim * H * W\n",
    "            flops += self.cross_attn.flops(H*W, self.win_size*self.win_size)\n",
    "\n",
    "        # norm1\n",
    "        flops += self.dim * H * W\n",
    "        # W-MSA/SW-MSA\n",
    "        flops += self.attn.flops(H, W)\n",
    "        # norm2\n",
    "        flops += self.dim * H * W\n",
    "        # mlp\n",
    "        flops += self.mlp.flops(H,W)\n",
    "        # print(\"LeWin:{%.2f}\"%(flops/1e9))\n",
    "        return flops\n",
    "\n",
    "\n",
    "#########################################\n",
    "########### Basic layer of Uformer ################\n",
    "class BasicUformerLayer(nn.Module):\n",
    "    def __init__(self, dim, output_dim, input_resolution, depth, num_heads, win_size,\n",
    "                 mlp_ratio=4., qkv_bias=True, qk_scale=None, drop=0., attn_drop=0.,\n",
    "                 drop_path=0., norm_layer=nn.LayerNorm, use_checkpoint=False,\n",
    "                 token_projection='linear',token_mlp='ffn', shift_flag=True,\n",
    "                 modulator=False,cross_modulator=False):\n",
    "\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "        self.input_resolution = input_resolution\n",
    "        self.depth = depth\n",
    "        self.use_checkpoint = use_checkpoint\n",
    "        # build blocks\n",
    "        if shift_flag:\n",
    "            self.blocks = nn.ModuleList([\n",
    "                LeWinTransformerBlock(dim=dim, input_resolution=input_resolution,\n",
    "                                    num_heads=num_heads, win_size=win_size,\n",
    "                                    shift_size=0 if (i % 2 == 0) else win_size // 2,\n",
    "                                    mlp_ratio=mlp_ratio,\n",
    "                                    qkv_bias=qkv_bias, qk_scale=qk_scale,\n",
    "                                    drop=drop, attn_drop=attn_drop,\n",
    "                                    drop_path=drop_path[i] if isinstance(drop_path, list) else drop_path,\n",
    "                                    norm_layer=norm_layer,token_projection=token_projection,token_mlp=token_mlp,\n",
    "                                    modulator=modulator,cross_modulator=cross_modulator)\n",
    "                for i in range(depth)])\n",
    "        else:\n",
    "            self.blocks = nn.ModuleList([\n",
    "                LeWinTransformerBlock(dim=dim, input_resolution=input_resolution,\n",
    "                                    num_heads=num_heads, win_size=win_size,\n",
    "                                    shift_size=0,\n",
    "                                    mlp_ratio=mlp_ratio,\n",
    "                                    qkv_bias=qkv_bias, qk_scale=qk_scale,\n",
    "                                    drop=drop, attn_drop=attn_drop,\n",
    "                                    drop_path=drop_path[i] if isinstance(drop_path, list) else drop_path,\n",
    "                                    norm_layer=norm_layer,token_projection=token_projection,token_mlp=token_mlp,\n",
    "                                    modulator=modulator,cross_modulator=cross_modulator)\n",
    "            for i in range(depth)])\n",
    "\n",
    "    def extra_repr(self) -> str:\n",
    "        return f\"dim={self.dim}, input_resolution={self.input_resolution}, depth={self.depth}\"    \n",
    "\n",
    "    def forward(self, x, mask=None):\n",
    "        for blk in self.blocks:\n",
    "            if self.use_checkpoint:\n",
    "                x = checkpoint.checkpoint(blk, x)\n",
    "            else:\n",
    "                x = blk(x,mask)\n",
    "        return x\n",
    "\n",
    "    def flops(self):\n",
    "        flops = 0\n",
    "        for blk in self.blocks:\n",
    "            flops += blk.flops()\n",
    "        return flops\n",
    "\n",
    "\n",
    "class Uformer(nn.Module):\n",
    "    def __init__(self, img_size=256, in_chans=3, dd_in=3,\n",
    "                 embed_dim=32, depths=[2, 2, 2, 2, 2, 2, 2, 2, 2], num_heads=[1, 2, 4, 8, 16, 16, 8, 4, 2],\n",
    "                 win_size=8, mlp_ratio=4., qkv_bias=True, qk_scale=None,\n",
    "                 drop_rate=0., attn_drop_rate=0., drop_path_rate=0.1,\n",
    "                 norm_layer=nn.LayerNorm, patch_norm=True,\n",
    "                 use_checkpoint=False, token_projection='linear', token_mlp='leff',\n",
    "                 dowsample=Downsample, upsample=Upsample, shift_flag=True, modulator=False, \n",
    "                 cross_modulator=False, **kwargs):\n",
    "        super().__init__()\n",
    "\n",
    "        self.num_enc_layers = len(depths)//2\n",
    "        self.num_dec_layers = len(depths)//2\n",
    "        self.embed_dim = embed_dim\n",
    "        self.patch_norm = patch_norm\n",
    "        self.mlp_ratio = mlp_ratio\n",
    "        self.token_projection = token_projection\n",
    "        self.mlp = token_mlp\n",
    "        self.win_size =win_size\n",
    "        self.reso = img_size\n",
    "        self.pos_drop = nn.Dropout(p=drop_rate)\n",
    "        self.dd_in = dd_in\n",
    "\n",
    "        # stochastic depth\n",
    "        enc_dpr = [x.item() for x in torch.linspace(0, drop_path_rate, sum(depths[:self.num_enc_layers]))] \n",
    "        conv_dpr = [drop_path_rate]*depths[4]\n",
    "        dec_dpr = enc_dpr[::-1]\n",
    "\n",
    "        # build layers\n",
    "\n",
    "        # Input/Output\n",
    "        self.input_proj = InputProj(in_channel=dd_in, out_channel=embed_dim, kernel_size=3, stride=1, act_layer=nn.LeakyReLU)\n",
    "        self.output_proj = OutputProj(in_channel=2*embed_dim, out_channel=in_chans, kernel_size=3, stride=1)\n",
    "        \n",
    "        # Encoder\n",
    "        self.encoderlayer_0 = BasicUformerLayer(dim=embed_dim,\n",
    "                            output_dim=embed_dim,\n",
    "                            input_resolution=(img_size,\n",
    "                                                img_size),\n",
    "                            depth=depths[0],\n",
    "                            num_heads=num_heads[0],\n",
    "                            win_size=win_size,\n",
    "                            mlp_ratio=self.mlp_ratio,\n",
    "                            qkv_bias=qkv_bias, qk_scale=qk_scale,\n",
    "                            drop=drop_rate, attn_drop=attn_drop_rate,\n",
    "                            drop_path=enc_dpr[sum(depths[:0]):sum(depths[:1])],\n",
    "                            norm_layer=norm_layer,\n",
    "                            use_checkpoint=use_checkpoint,\n",
    "                            token_projection=token_projection,token_mlp=token_mlp,shift_flag=shift_flag)\n",
    "        self.dowsample_0 = dowsample(embed_dim, embed_dim*2)\n",
    "        self.encoderlayer_1 = BasicUformerLayer(dim=embed_dim*2,\n",
    "                            output_dim=embed_dim*2,\n",
    "                            input_resolution=(img_size // 2,\n",
    "                                                img_size // 2),\n",
    "                            depth=depths[1],\n",
    "                            num_heads=num_heads[1],\n",
    "                            win_size=win_size,\n",
    "                            mlp_ratio=self.mlp_ratio,\n",
    "                            qkv_bias=qkv_bias, qk_scale=qk_scale,\n",
    "                            drop=drop_rate, attn_drop=attn_drop_rate,\n",
    "                            drop_path=enc_dpr[sum(depths[:1]):sum(depths[:2])],\n",
    "                            norm_layer=norm_layer,\n",
    "                            use_checkpoint=use_checkpoint,\n",
    "                            token_projection=token_projection,token_mlp=token_mlp,shift_flag=shift_flag)\n",
    "        self.dowsample_1 = dowsample(embed_dim*2, embed_dim*4)\n",
    "        self.encoderlayer_2 = BasicUformerLayer(dim=embed_dim*4,\n",
    "                            output_dim=embed_dim*4,\n",
    "                            input_resolution=(img_size // (2 ** 2),\n",
    "                                                img_size // (2 ** 2)),\n",
    "                            depth=depths[2],\n",
    "                            num_heads=num_heads[2],\n",
    "                            win_size=win_size,\n",
    "                            mlp_ratio=self.mlp_ratio,\n",
    "                            qkv_bias=qkv_bias, qk_scale=qk_scale,\n",
    "                            drop=drop_rate, attn_drop=attn_drop_rate,\n",
    "                            drop_path=enc_dpr[sum(depths[:2]):sum(depths[:3])],\n",
    "                            norm_layer=norm_layer,\n",
    "                            use_checkpoint=use_checkpoint,\n",
    "                            token_projection=token_projection,token_mlp=token_mlp,shift_flag=shift_flag)\n",
    "        self.dowsample_2 = dowsample(embed_dim*4, embed_dim*8)\n",
    "        self.encoderlayer_3 = BasicUformerLayer(dim=embed_dim*8,\n",
    "                            output_dim=embed_dim*8,\n",
    "                            input_resolution=(img_size // (2 ** 3),\n",
    "                                                img_size // (2 ** 3)),\n",
    "                            depth=depths[3],\n",
    "                            num_heads=num_heads[3],\n",
    "                            win_size=win_size,\n",
    "                            mlp_ratio=self.mlp_ratio,\n",
    "                            qkv_bias=qkv_bias, qk_scale=qk_scale,\n",
    "                            drop=drop_rate, attn_drop=attn_drop_rate,\n",
    "                            drop_path=enc_dpr[sum(depths[:3]):sum(depths[:4])],\n",
    "                            norm_layer=norm_layer,\n",
    "                            use_checkpoint=use_checkpoint,\n",
    "                            token_projection=token_projection,token_mlp=token_mlp,shift_flag=shift_flag)\n",
    "        self.dowsample_3 = dowsample(embed_dim*8, embed_dim*16)\n",
    "\n",
    "        # Bottleneck\n",
    "        self.conv = BasicUformerLayer(dim=embed_dim*16,\n",
    "                            output_dim=embed_dim*16,\n",
    "                            input_resolution=(img_size // (2 ** 4),\n",
    "                                                img_size // (2 ** 4)),\n",
    "                            depth=depths[4],\n",
    "                            num_heads=num_heads[4],\n",
    "                            win_size=win_size,\n",
    "                            mlp_ratio=self.mlp_ratio,\n",
    "                            qkv_bias=qkv_bias, qk_scale=qk_scale,\n",
    "                            drop=drop_rate, attn_drop=attn_drop_rate,\n",
    "                            drop_path=conv_dpr,\n",
    "                            norm_layer=norm_layer,\n",
    "                            use_checkpoint=use_checkpoint,\n",
    "                            token_projection=token_projection,token_mlp=token_mlp,shift_flag=shift_flag)\n",
    "\n",
    "        # Decoder\n",
    "        self.upsample_0 = upsample(embed_dim*16, embed_dim*8)\n",
    "        self.decoderlayer_0 = BasicUformerLayer(dim=embed_dim*16,\n",
    "                            output_dim=embed_dim*16,\n",
    "                            input_resolution=(img_size // (2 ** 3),\n",
    "                                                img_size // (2 ** 3)),\n",
    "                            depth=depths[5],\n",
    "                            num_heads=num_heads[5],\n",
    "                            win_size=win_size,\n",
    "                            mlp_ratio=self.mlp_ratio,\n",
    "                            qkv_bias=qkv_bias, qk_scale=qk_scale,\n",
    "                            drop=drop_rate, attn_drop=attn_drop_rate,\n",
    "                            drop_path=dec_dpr[:depths[5]],\n",
    "                            norm_layer=norm_layer,\n",
    "                            use_checkpoint=use_checkpoint,\n",
    "                            token_projection=token_projection,token_mlp=token_mlp,shift_flag=shift_flag,\n",
    "                            modulator=modulator,cross_modulator=cross_modulator)\n",
    "        self.upsample_1 = upsample(embed_dim*16, embed_dim*4)\n",
    "        self.decoderlayer_1 = BasicUformerLayer(dim=embed_dim*8,\n",
    "                            output_dim=embed_dim*8,\n",
    "                            input_resolution=(img_size // (2 ** 2),\n",
    "                                                img_size // (2 ** 2)),\n",
    "                            depth=depths[6],\n",
    "                            num_heads=num_heads[6],\n",
    "                            win_size=win_size,\n",
    "                            mlp_ratio=self.mlp_ratio,\n",
    "                            qkv_bias=qkv_bias, qk_scale=qk_scale,\n",
    "                            drop=drop_rate, attn_drop=attn_drop_rate,\n",
    "                            drop_path=dec_dpr[sum(depths[5:6]):sum(depths[5:7])],\n",
    "                            norm_layer=norm_layer,\n",
    "                            use_checkpoint=use_checkpoint,\n",
    "                            token_projection=token_projection,token_mlp=token_mlp,shift_flag=shift_flag,\n",
    "                            modulator=modulator,cross_modulator=cross_modulator)\n",
    "        self.upsample_2 = upsample(embed_dim*8, embed_dim*2)\n",
    "        self.decoderlayer_2 = BasicUformerLayer(dim=embed_dim*4,\n",
    "                            output_dim=embed_dim*4,\n",
    "                            input_resolution=(img_size // 2,\n",
    "                                                img_size // 2),\n",
    "                            depth=depths[7],\n",
    "                            num_heads=num_heads[7],\n",
    "                            win_size=win_size,\n",
    "                            mlp_ratio=self.mlp_ratio,\n",
    "                            qkv_bias=qkv_bias, qk_scale=qk_scale,\n",
    "                            drop=drop_rate, attn_drop=attn_drop_rate,\n",
    "                            drop_path=dec_dpr[sum(depths[5:7]):sum(depths[5:8])],\n",
    "                            norm_layer=norm_layer,\n",
    "                            use_checkpoint=use_checkpoint,\n",
    "                            token_projection=token_projection,token_mlp=token_mlp,shift_flag=shift_flag,\n",
    "                            modulator=modulator,cross_modulator=cross_modulator)\n",
    "        self.upsample_3 = upsample(embed_dim*4, embed_dim)\n",
    "        self.decoderlayer_3 = BasicUformerLayer(dim=embed_dim*2,\n",
    "                            output_dim=embed_dim*2,\n",
    "                            input_resolution=(img_size,\n",
    "                                                img_size),\n",
    "                            depth=depths[8],\n",
    "                            num_heads=num_heads[8],\n",
    "                            win_size=win_size,\n",
    "                            mlp_ratio=self.mlp_ratio,\n",
    "                            qkv_bias=qkv_bias, qk_scale=qk_scale,\n",
    "                            drop=drop_rate, attn_drop=attn_drop_rate,\n",
    "                            drop_path=dec_dpr[sum(depths[5:8]):sum(depths[5:9])],\n",
    "                            norm_layer=norm_layer,\n",
    "                            use_checkpoint=use_checkpoint,\n",
    "                            token_projection=token_projection,token_mlp=token_mlp,shift_flag=shift_flag,\n",
    "                            modulator=modulator,cross_modulator=cross_modulator)\n",
    "\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    def _init_weights(self, m):\n",
    "        if isinstance(m, nn.Linear):\n",
    "            trunc_normal_(m.weight, std=.02)\n",
    "            if isinstance(m, nn.Linear) and m.bias is not None:\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "        elif isinstance(m, nn.LayerNorm):\n",
    "            nn.init.constant_(m.bias, 0)\n",
    "            nn.init.constant_(m.weight, 1.0)\n",
    "\n",
    "    @torch.jit.ignore\n",
    "    def no_weight_decay(self):\n",
    "        return {'absolute_pos_embed'}\n",
    "\n",
    "    @torch.jit.ignore\n",
    "    def no_weight_decay_keywords(self):\n",
    "        return {'relative_position_bias_table'}\n",
    "\n",
    "    def extra_repr(self) -> str:\n",
    "        return f\"embed_dim={self.embed_dim}, token_projection={self.token_projection}, token_mlp={self.mlp},win_size={self.win_size}\"\n",
    "\n",
    "    def forward(self, x, mask=None):\n",
    "        # Input Projection\n",
    "        y = self.input_proj(x)\n",
    "        y = self.pos_drop(y)\n",
    "        #Encoder\n",
    "        conv0 = self.encoderlayer_0(y,mask=mask)\n",
    "        pool0 = self.dowsample_0(conv0)\n",
    "        conv1 = self.encoderlayer_1(pool0,mask=mask)\n",
    "        pool1 = self.dowsample_1(conv1)\n",
    "        conv2 = self.encoderlayer_2(pool1,mask=mask)\n",
    "        pool2 = self.dowsample_2(conv2)\n",
    "        conv3 = self.encoderlayer_3(pool2,mask=mask)\n",
    "        pool3 = self.dowsample_3(conv3)\n",
    "\n",
    "        # Bottleneck\n",
    "        conv4 = self.conv(pool3, mask=mask)\n",
    "\n",
    "        #Decoder\n",
    "        up0 = self.upsample_0(conv4)\n",
    "        deconv0 = torch.cat([up0,conv3],-1)\n",
    "        deconv0 = self.decoderlayer_0(deconv0,mask=mask)\n",
    "        \n",
    "        up1 = self.upsample_1(deconv0)\n",
    "        deconv1 = torch.cat([up1,conv2],-1)\n",
    "        deconv1 = self.decoderlayer_1(deconv1,mask=mask)\n",
    "\n",
    "        up2 = self.upsample_2(deconv1)\n",
    "        deconv2 = torch.cat([up2,conv1],-1)\n",
    "        deconv2 = self.decoderlayer_2(deconv2,mask=mask)\n",
    "\n",
    "        up3 = self.upsample_3(deconv2)\n",
    "        deconv3 = torch.cat([up3,conv0],-1)\n",
    "        deconv3 = self.decoderlayer_3(deconv3,mask=mask)\n",
    "\n",
    "        # Output Projection\n",
    "        y = self.output_proj(deconv3)\n",
    "        return x + y if self.dd_in ==3 else y\n",
    "\n",
    "    def flops(self):\n",
    "        flops = 0\n",
    "        # Input Projection\n",
    "        flops += self.input_proj.flops(self.reso,self.reso)\n",
    "        # Encoder\n",
    "        flops += self.encoderlayer_0.flops()+self.dowsample_0.flops(self.reso,self.reso)\n",
    "        flops += self.encoderlayer_1.flops()+self.dowsample_1.flops(self.reso//2,self.reso//2)\n",
    "        flops += self.encoderlayer_2.flops()+self.dowsample_2.flops(self.reso//2**2,self.reso//2**2)\n",
    "        flops += self.encoderlayer_3.flops()+self.dowsample_3.flops(self.reso//2**3,self.reso//2**3)\n",
    "\n",
    "        # Bottleneck\n",
    "        flops += self.conv.flops()\n",
    "\n",
    "        # Decoder\n",
    "        flops += self.upsample_0.flops(self.reso//2**4,self.reso//2**4)+self.decoderlayer_0.flops()\n",
    "        flops += self.upsample_1.flops(self.reso//2**3,self.reso//2**3)+self.decoderlayer_1.flops()\n",
    "        flops += self.upsample_2.flops(self.reso//2**2,self.reso//2**2)+self.decoderlayer_2.flops()\n",
    "        flops += self.upsample_3.flops(self.reso//2,self.reso//2)+self.decoderlayer_3.flops()\n",
    "        \n",
    "        # Output Projection\n",
    "        flops += self.output_proj.flops(self.reso,self.reso)\n",
    "        return flops\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    input_size = 256\n",
    "    arch = Uformer\n",
    "    depths=[2, 2, 2, 2, 2, 2, 2, 2, 2]\n",
    "    model_restoration = Uformer(img_size=input_size, embed_dim=16,depths=depths,\n",
    "                 win_size=8, mlp_ratio=4., token_projection='linear', token_mlp='leff', modulator=True, shift_flag=False)\n",
    "    print(model_restoration)\n",
    "    # from ptflops import get_model_complexity_info\n",
    "    # macs, params = get_model_complexity_info(model_restoration, (3, input_size, input_size), as_strings=True,\n",
    "    #                                             print_per_layer_stat=True, verbose=True)\n",
    "    # print('{:<30}  {:<8}'.format('Computational complexity: ', macs))\n",
    "    # print('{:<30}  {:<8}'.format('Number of parameters: ', params))\n",
    "    print('# model_restoration parameters: %.2f M'%(sum(param.numel() for param in model_restoration.parameters())/ 1e6))\n",
    "    print(\"number of GFLOPs: %.2f G\"%(model_restoration.flops() / 1e9))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9116fc67e4256ae2032cd97a5d43eaf97776cee9d03cd8e1c3e900c0daf90596"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
